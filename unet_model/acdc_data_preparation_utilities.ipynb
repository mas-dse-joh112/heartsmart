{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show tensorflow\n",
    "\n",
    "!pip show tensorflow-gpu\n",
    "\n",
    "!pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#import tensorflow as tf\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, device_count = {'GPU':3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = tf.ConfigProto(\n",
    "#        device_count = {'GPU': 0}\n",
    "#    )\n",
    "#sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully imported packages!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import cv2 \n",
    "import re, sys\n",
    "import fnmatch, shutil, subprocess\n",
    "from IPython.utils import io\n",
    "import glob\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, concatenate, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "#Fix the random seeds for numpy (this is for Keras) and for tensorflow backend to reduce the run-to-run variance\n",
    "from numpy.random import seed\n",
    "seed(100)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\nSuccessfully imported packages!!!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.training_utils import multi_gpu_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.1  # train/test split ratio for Sunnybrook and ACDC data\n",
    "\n",
    "BASE_DIR = \"/opt/output/\"\n",
    "ACDC_SOURCE = \"acdc\"\n",
    "TRAIN_IMG_DIR = BASE_DIR + ACDC_SOURCE + \"/norm/1/3/images/\"\n",
    "TRAIN_LBL_DIR = BASE_DIR + ACDC_SOURCE + \"/norm/1/3/labels/\"\n",
    "\n",
    "TEST_IMG_DIR = BASE_DIR + ACDC_SOURCE + \"/norm/1/3/images/\"\n",
    "PRED_RESULT_DIR = BASE_DIR + ACDC_SOURCE + \"/norm/1/3/images/\"\n",
    "\n",
    "# UNET_TRAIN_DIR = BASE_DIR + SOURCE + \"/unet_model/data/\"\n",
    "# UNET_MODEL_DIR = BASE_DIR + SOURCE + \"/unet_model/models/\"\n",
    "\n",
    "UNET_TRAIN_DIR = \"/masvol/heartsmart/unet_model/data/\"\n",
    "UNET_MODEL_DIR = \"/masvol/heartsmart/unet_model/models/\"\n",
    "\n",
    "DSB_SOURCE = \"dsb\"\n",
    "DSB_TRAIN_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/train\"\n",
    "DSB_VAL_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/validate\"\n",
    "DSB_TEST_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/test\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Methods to extract acdc contour files and corresponding image files \n",
    "# and Save them as numpy arrays in memory\n",
    "#\n",
    "###################################\n",
    "\n",
    "def shrink_case(case):\n",
    "    toks = case.split(\"-\")\n",
    "    \n",
    "    def shrink_if_number(x):\n",
    "        try:\n",
    "            cvt = int(x)\n",
    "            return str(cvt)\n",
    "        except ValueError:\n",
    "            return x\n",
    "\n",
    "    return \"-\".join([shrink_if_number(t) for t in toks])\n",
    "\n",
    "class Contour(object):\n",
    "    def __init__(self, ctr_path):\n",
    "        self.ctr_path = ctr_path\n",
    "        #print (ctr_path)\n",
    "        match = re.search(r\"/([^/]*)/patient\\d+_slice(\\d+)_frame(\\d+)_label_fix.nii.npy\", ctr_path)\n",
    "        self.case = shrink_case(match.group(1))\n",
    "        self.record = int(match.group(2))\n",
    "        self.img_no = int(match.group(3))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"<Contour for case %s, record %d image %d>\" % (self.case, self.record, self.img_no)\n",
    "    \n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def load_contour(contour, img_path, crop_size):\n",
    "    # file = IM-0851-0127.dcm.npy\n",
    "    filename = \"%s_slice%s_frame%d.nii.npy\" % (contour.case,contour.record,contour.img_no)\n",
    "    full_path = os.path.join(img_path, contour.case, filename)\n",
    "    img = np.load(full_path)\n",
    "    label = np.load(contour.ctr_path)\n",
    "    height, width = img.shape\n",
    "    height_l, width_l = label.shape\n",
    "    \n",
    "    if height != crop_size or width != crop_size:\n",
    "        #print (\"img: \", contour.img_no, height, width)\n",
    "        #print (\"lbl: \", height_l, width_l)\n",
    "        img = crop_center(img,crop_size,crop_size)\n",
    "        label = crop_center(label,crop_size,crop_size)\n",
    "        \n",
    "    return img, label, full_path\n",
    "   \n",
    "def get_all_contours(contour_path):\n",
    "    contours = [os.path.join(dirpath,f) \n",
    "            for files in glob.glob(TRAIN_LBL_DIR+\"/*\") \n",
    "            for dirpath, dirname, infiles in os.walk(files) \n",
    "            for f in infiles if f.endswith('label_fix.nii.npy')]\n",
    "    \n",
    "    print(\"Number of examples: {:d}\".format(len(contours)))\n",
    "    print(\"Shuffle data\")\n",
    "    \n",
    "    np.random.shuffle(contours)\n",
    "    print (contours[0], contours[-1])\n",
    "    \n",
    "    extracted = list(map(Contour, contours))\n",
    "    print (\"Contour 0 :\", extracted[0].case, extracted[0].record, extracted[0].img_no)\n",
    "    print (\"Contour -1 :\", extracted[-1].case, extracted[-1].record, extracted[-1].img_no) \n",
    "    return extracted\n",
    "\n",
    "\n",
    "def get_contours_and_images(contours, img_path, crop_size):\n",
    "\n",
    "    num_contours = len(contours)\n",
    "    print(\"Processing {:d} images and labels...\".format(num_contours))        \n",
    "    imgs, labels = [], []\n",
    "        \n",
    "    for idx,ctr in enumerate(contours):\n",
    "        #try:\n",
    "            filename = \"%s_slice%s_frame%d.nii.npy\" % (ctr.case,ctr.record,ctr.img_no)\n",
    "            full_path = os.path.join(img_path, ctr.case, filename)\n",
    "            img = np.load(full_path)\n",
    "            x,y = img.shape\n",
    "\n",
    "            if x < crop_size or y < crop_size:\n",
    "                continue\n",
    "\n",
    "            img, label, fullpath = load_contour(ctr, img_path, crop_size)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if idx % (num_contours//5) == 0: # print up to 5 images\n",
    "                print (img.shape, fullpath)\n",
    "                f, axs = plt.subplots(1,3,figsize=(12,12))\n",
    "                plt.subplot(131),plt.imshow(img, cmap = 'gray')\n",
    "                plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "                plt.subplot(132),plt.imshow(label, cmap = 'gray')\n",
    "                plt.title('label'), plt.xticks([]), plt.yticks([])\n",
    "                plt.subplot(133),plt.imshow(img, cmap = 'gray')\n",
    "                plt.imshow(label, 'jet', interpolation='none', alpha=0.5)\n",
    "                plt.title('label'), plt.xticks([]), plt.yticks([])\n",
    "                plt.show()\n",
    "\n",
    "    print(\"Processed {:d} images and labels...\".format(len(imgs))) \n",
    "    return imgs, labels\n",
    "\n",
    "def save_training_data(imgs, lbls, save_file_path, file_prefix, image_size):\n",
    "    rows = image_size\n",
    "    cols = image_size\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print(\"Creating training data..input size : \",len(imgs))\n",
    "    print('-'*30)\n",
    "    print(\"Converting data to np array\")\n",
    "    \n",
    "    imgdatas = np.ndarray((len(imgs),rows,cols,1), dtype=np.int)\n",
    "    \n",
    "    imglabels = np.ndarray((len(imgs),rows,cols,1), dtype=np.uint8)\n",
    "    \n",
    "    for idx in range(len(imgs)):\n",
    "        img = imgs[idx]\n",
    "        label = lbls[idx]\n",
    "        img = img_to_array(img)\n",
    "        label = img_to_array(label)\n",
    "        \n",
    "        try:\n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        \n",
    "    imgfile = save_file_path + file_prefix +\"_images.npy\"\n",
    "    print (imgfile)\n",
    "    lblfile = save_file_path + file_prefix +\"_labels.npy\"\n",
    "    np.save(imgfile, imgdatas)\n",
    "    np.save(lblfile, imglabels)\n",
    "\n",
    "    print (\"Shape of data & label np arrays : \", imgdatas.shape, imglabels.shape)\n",
    "    print (imgdatas.max(), imgdatas.min(), imglabels.max(), imglabels.min())\n",
    "    print('Saved data as: ', imgfile, lblfile )\n",
    "\n",
    "\n",
    "def extract_acdc_training_data(crop_size=256): \n",
    "    SPLIT_RATIO = TRAIN_TEST_SPLIT_RATIO  # train/test split ratio\n",
    "    print(\"Mapping ground truth contours to images...\")\n",
    "    \n",
    "    ctrs = get_all_contours(TRAIN_LBL_DIR)\n",
    "    print(\"Done mapping ground truth contours to images\")\n",
    "    \n",
    "    test_ctrs = ctrs[0:int(SPLIT_RATIO*len(ctrs))]\n",
    "    train_ctrs = ctrs[int(SPLIT_RATIO*len(ctrs)):]\n",
    "    print(\"Split train_set:%d, test_set:%d\"%(len(train_ctrs), len(test_ctrs)))\n",
    "    print (\"Extracting Training Images and Labels\")\n",
    "    \n",
    "    train_imgs, train_labels = get_contours_and_images(train_ctrs, TRAIN_IMG_DIR, crop_size)\n",
    "    print (\"Extracting Test Images and Labels\")\n",
    "    \n",
    "    test_imgs, test_labels = get_contours_and_images(test_ctrs, TRAIN_IMG_DIR, crop_size)\n",
    "    print(\"Extracted Images train_set:%d, test_set:%d\"%(len(train_imgs), len(test_imgs)))\n",
    "    \n",
    "    return train_imgs, train_labels, test_imgs, test_labels \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ##Get acdc images and labels with crop from center to get 256x256 images\n",
    "    train_imgs, train_labels, test_imgs, test_labels = extract_acdc_training_data(crop_size=256)\n",
    "\n",
    "    ##Get acdc images and labels with crop from center to get 176x176 images\n",
    "\n",
    "    train_imgs2, train_labels2, test_imgs2, test_labels2 = extract_acdc_training_data(crop_size=176)\n",
    "\n",
    "    ### Create 256x256 size train/test data in 4d tensor shape and save them\n",
    "    save_location = UNET_TRAIN_DIR\n",
    "    tr_file_prefix = ACDC_SOURCE + \"_256_train\"\n",
    "    tst_file_prefix = ACDC_SOURCE + \"_256_test\"\n",
    "    save_training_data(train_imgs, train_labels, save_location, tr_file_prefix, image_size = 256)\n",
    "    save_training_data(test_imgs, test_labels, save_location, tst_file_prefix, image_size = 256)\n",
    "\n",
    "    ### Create 180x180 size train/test data in 4d tensor shape and save them\n",
    "    tr_file_prefix = ACDC_SOURCE + \"_176_train\"\n",
    "    tst_file_prefix = ACDC_SOURCE + \"_176_test\"\n",
    "\n",
    "    save_training_data(train_imgs2, train_labels2, save_location, tr_file_prefix, image_size = 176)\n",
    "    save_training_data(test_imgs2, test_labels2, save_location, tst_file_prefix, image_size = 176)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#\n",
    "# Methods to load 4d np array for images from ./data directory\n",
    "# 4D tensor with shape: (samples, rows, cols, channels=1)\n",
    "#\n",
    "#########################################\n",
    "\n",
    "def load_images_and_labels(data):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images and labels...')\n",
    "    print('-'*30)\n",
    "    imgfile = data[\"images\"]\n",
    "    labelfile = data[\"labels\"]\n",
    "    print (\"Loading files : \", imgfile, labelfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    lb = np.load(labelfile)\n",
    "    images = im.astype('float32')\n",
    "    labels = lb.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    print(\"shape, max, min, mean of labels :\", labels.shape, labels.max(), labels.min(), labels.mean())\n",
    "    return images2, labels\n",
    "\n",
    "\n",
    "def load_images(imgfile):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images ...')\n",
    "    print('-'*30)\n",
    "    print (\"Loading files : \", imgfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    images = im.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    return images2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load np arrays of images and labels...\n",
      "------------------------------\n",
      "Loading files :  /masvol/heartsmart/unet_model/data/acdc_256_test_images.npy /masvol/heartsmart/unet_model/data/acdc_256_test_labels.npy\n",
      "shape, max, min, mean of original image set: (171, 256, 256, 1) 1693.0 0.0 78.67779\n",
      "shape, max, min, mean after normalization  : (171, 256, 256, 1) 1.0 0.0 0.21236953\n",
      "shape, max, min, mean of labels : (171, 256, 256, 1) 1.0 0.0 0.024848448\n"
     ]
    }
   ],
   "source": [
    "acdc_test_data = {}\n",
    "acdc_test_data[\"images\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_256_test_images.npy\"\n",
    "acdc_test_data[\"labels\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_256_test_labels.npy\"\n",
    "acdc_test_img, acdc_test_lbl = load_images_and_labels(acdc_test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
