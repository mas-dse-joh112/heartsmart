{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys, math\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#\n",
    "# Methods to load 4d np array for images from ./data directory\n",
    "# 4D tensor with shape: (samples, rows, cols, channels=1)\n",
    "#\n",
    "#########################################\n",
    "\n",
    "def load_images_and_labels(data):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images and labels...')\n",
    "    print('-'*30)\n",
    "    imgfile = data[\"images\"]\n",
    "    labelfile = data[\"labels\"]\n",
    "    print (\"Loading files : \", imgfile, labelfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    lb = np.load(labelfile)\n",
    "    images = im.astype('float32')\n",
    "    labels = lb.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    print(\"shape, max, min, mean of labels :\", labels.shape, labels.max(), labels.min(), labels.mean())\n",
    "    return images2, labels\n",
    "\n",
    "def load_images_and_labels_no_preproc(data):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images and labels...')\n",
    "    print('-'*30)\n",
    "    imgfile = data[\"images\"]\n",
    "    labelfile = data[\"labels\"]\n",
    "    print (\"Loading files : \", imgfile, labelfile)\n",
    "\n",
    "    images = np.load(imgfile)\n",
    "    labels = np.load(labelfile)\n",
    "#     im = np.load(imgfile)\n",
    "#     lb = np.load(labelfile)\n",
    "#     images = im.astype('float32')\n",
    "#     labels = lb.astype('float32')\n",
    "    \n",
    "#     ##Normalize the pixel values, (between 0..1)\n",
    "#     x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "#     x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "#     images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "#    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    print(\"shape, max, min, mean of labels :\", labels.shape, labels.max(), labels.min(), labels.mean())\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_images(imgfile):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images ...')\n",
    "    print('-'*30)\n",
    "    print (\"Loading files : \", imgfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    images = im.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    return images2\n",
    "\n",
    "\n",
    "\n",
    "def plot_accuracy_and_loss(file_p):\n",
    "    try:\n",
    "        with open(file_p, 'r') as file:\n",
    "            history = json.load(file)\n",
    "    except (OSError, ValueError):  # file does not exist or is empty/invalid\n",
    "        print (\"File does not exist\")\n",
    "        \n",
    "    # list all data in history\n",
    "    print(history.keys())\n",
    "    print('-'*30)\n",
    "    print (\"Values at first and last epoch\")\n",
    "    print('-'*30)\n",
    "    for key in history:\n",
    "        print (key, \" : \", history[key][0], \",\", history[key][-1])\n",
    "    print('-'*30) \n",
    "    print('-'*30)\n",
    "    # summarize history for accuracy\n",
    "    if 'dice_coeff' in history.keys():\n",
    "        plt.plot(history['dice_coeff'])\n",
    "        plt.plot(history['val_dice_coeff'])\n",
    "        plt.title('model accuracy(dice_coeff)')\n",
    "    elif 'val_acc' in history.keys():\n",
    "        plt.plot(history['acc'])\n",
    "        plt.plot(history['val_acc'])\n",
    "        plt.title('Model accuracy')\n",
    "    elif 'categorical_accuracy' in history.keys():\n",
    "        plt.plot(history['categorical_accuracy'])\n",
    "        plt.plot(history['val_categorical_accuracy'])\n",
    "        plt.title('categorical_accuracy')\n",
    "    elif 'binary_accuracy' in history.keys():\n",
    "        plt.plot(history['binary_accuracy'])\n",
    "        plt.plot(history['val_binary_accuracy'])\n",
    "        plt.title('Minary_accuracy')\n",
    "    else : \n",
    "        print (\"new loss function, not in the list\")\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.grid()\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def show_performance_statistics(file_p):\n",
    "    perf_list = ['logloss', 'weighted_logloss', 'accuracy', 'weighted_accuracy','true_positive', 'false_positive', 'true_negative','false_negative', \\\n",
    "                 'precision','recall', 'f1_score' ]\n",
    "    try:\n",
    "        with open(file_p, 'r') as file:\n",
    "            perf = json.load(file)\n",
    "    except (OSError, ValueError):  # file does not exist or is empty/invalid\n",
    "        print (\"File does not exist\")\n",
    "        perf = {}\n",
    "\n",
    "    print('-'*30)\n",
    "    for key in perf_list:\n",
    "        if key in perf.keys():\n",
    "            print (key, \" : \", perf[key])\n",
    "    print('-'*30) \n",
    "    print('-'*30)\n",
    "    # list all data in history\n",
    "    \n",
    "def get_performance_statistics(y_true_f, y_pred_f):\n",
    "#     y_true = np.load(y_true_f)\n",
    "#     y_pred = np.load(y_pred_f)\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    sample_weights = np.copy(y_true)\n",
    "    sample_weights[sample_weights == 1] = 1.\n",
    "    sample_weights[sample_weights == 0] = .2\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    y_pred[y_pred<=0.] = epsilon\n",
    "    y_pred[y_pred>=1.] = 1. -epsilon\n",
    "    \n",
    "    perf = {}\n",
    "    \n",
    "    score = log_loss (y_true, y_pred)\n",
    "    score2 = log_loss (y_true, y_pred, sample_weight = sample_weights)\n",
    "    perf[\"logloss\"] = score\n",
    "    perf[\"weighted_logloss\"] = score2\n",
    "    perf[\"accuracy\"] = math.exp(-score)\n",
    "    perf[\"weighted_accuracy\"] = math.exp(-score2)\n",
    "\n",
    "    y_pred = np.round(y_pred)\n",
    "    perf[\"precision\"] = precision_score(y_true, y_pred, average=\"binary\")\n",
    "    perf[\"recall\"] = recall_score(y_true, y_pred, average=\"binary\")\n",
    "    perf[\"f1_score\"] = f1_score(y_true, y_pred, average=\"binary\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    perf[\"true_positive\"] = cm[1][1]\n",
    "    perf[\"false_positive\"] = cm[0][1]\n",
    "    perf[\"true_negative\"] = cm[0][0]\n",
    "    perf[\"false_negative\"] = cm[1][0]\n",
    "    #cm.print_stats()\n",
    "    return perf\n",
    "    \n",
    "def evaluate_performance2(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    y_pred_r = np.round(y_pred_f)\n",
    "\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred_f[y_pred_f<=0.] = epsilon\n",
    "    y_pred_f[y_pred_f>=1.] = 1. -epsilon\n",
    "    #y_pred = K.clip(y_pred_f, epsilon, 1. - epsilon)\n",
    "    #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    perf = {}\n",
    "    result = []\n",
    "    result2 = []\n",
    "    \n",
    "    true_p = 0.0\n",
    "    true_n = 0.0\n",
    "    false_p = 0.0\n",
    "    false_n = 0.0\n",
    "    for i in range (len(y_pred_f)):\n",
    "        result.append (y_true_f[i] * np.log(y_pred_f[i]) + (1 - y_true_f[i]) * np.log(1 - y_pred_f[i]))\n",
    "        result2.append (y_true_f[i] * np.log2(y_pred_f[i]) + (1 - y_true_f[i]) * np.log2(1 - y_pred_f[i]))\n",
    "\n",
    "        if (y_pred_r[i] == 0 and y_true_f[i] == 0):\n",
    "            true_n += 1.\n",
    "        elif (y_pred_r[i] == 0 and y_true_f[i] == 1):\n",
    "            false_n += 1.\n",
    "        elif (y_pred_r[i] == 1 and y_true_f[i] == 1):\n",
    "            true_p += 1.\n",
    "        elif (y_pred_r[i] == 1 and y_true_f[i] == 0):\n",
    "            false_p += 1.\n",
    "            \n",
    "    loss = np.mean(result)\n",
    "    loss2 = np.mean(result2)\n",
    "    accuracy = (true_p + true_n)/(true_p + true_n + false_p + false_n)\n",
    "    precision = true_p/(true_p + false_p)\n",
    "    recall    = true_p/(true_p + false_n)\n",
    "    f1_score = (2 * precision * recall)/(precision+recall)\n",
    "    \n",
    "    print (len(result), sum(result))\n",
    "    print (\"true_pos : %d, false_pos : %d, true_neg  %d, false_neg : %d\"%(true_p, false_p, true_n, false_n))\n",
    "    print (\"accuracy : %f, precision : %f, recall  %f, f1_score : %f\"%(accuracy, precision, recall, f1_score))\n",
    "    print (\"logloss : %f, log2loss : %f \"%(loss, loss2))\n",
    "    perf[\"logloss\"] = loss\n",
    "    perf[\"log2loss\"] = loss2\n",
    "    perf[\"true_positive\"] = true_p\n",
    "    perf[\"false_positive\"] = false_p\n",
    "    perf[\"true_negative\"] = true_n\n",
    "    perf[\"false_negative\"] = false_n\n",
    "    perf[\"accuracy\"] = accuracy\n",
    "    perf[\"precision\"] = precision\n",
    "    perf[\"recall\"] = recall\n",
    "    perf[\"f1_score\"] = f1_score\n",
    "    \n",
    "    return perf\n",
    "\n",
    "def compute_performance_statistics (y_true_f, y_pred_f):\n",
    "    y_true = np.load(y_true_f)\n",
    "    y_pred = np.load(y_pred_f)\n",
    "    print (y_true.shape, y_pred.shape)\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    \n",
    "    weight = 0.8\n",
    "    sample_weights = np.copy(y_true)\n",
    "    sample_weights[sample_weights == 1] = 1.\n",
    "    sample_weights[sample_weights == 0] = .2\n",
    "    \n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    y_pred[y_pred<=0.] = epsilon\n",
    "    y_pred[y_pred>=1.] = 1. -epsilon\n",
    "    \n",
    "    print (y_true.shape, y_pred.shape)\n",
    "\n",
    "    score = log_loss (y_true, y_pred)\n",
    "    score2 = log_loss (y_true, y_pred, sample_weight = sample_weights)\n",
    "    acc = math.exp(-score)\n",
    "    acc2 = math.exp(-score2)\n",
    "    y_pred = np.round(y_pred)\n",
    "    print (\"log_loss : \", score,  \"  Accuracy: \", acc)\n",
    "    print (\"weighted log_loss : \", score2,  \"  Accuracy: \", acc2)\n",
    "    print(\"f1 score :\", f1_score(y_true, y_pred, average=\"binary\"))\n",
    "    print(\"precision :\", precision_score(y_true, y_pred, average=\"binary\"))\n",
    "    print(\"recall :\", recall_score(y_true, y_pred, average=\"binary\")) \n",
    "    \n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print (cm)\n",
    "    #cm.print_stats()\n",
    "    true_p = cm[1][1]\n",
    "    false_p = cm[0][1]\n",
    "    true_n = cm[0][0]\n",
    "    false_n = cm[1][0]\n",
    "    print (\"true_p = %d, false_p = %d, true_neg = %d, false_neg = %d\"%(true_p, false_p, true_n, false_n))\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def display_images_labels (image_file, label_file,  num_images = 4, random_images = False):\n",
    "    ts = np.load(image_file)\n",
    "    tl = np.load(label_file)\n",
    "    samples, x, y, z = tl.shape\n",
    "\n",
    "    display_list = []\n",
    "\n",
    "    if random_images == True:\n",
    "        display_list = random.sample(range(0, samples), num_images)\n",
    "    else :\n",
    "        display_list = [i for i in range (num_images)]\n",
    "\n",
    "    for i in display_list:\n",
    "        f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "        plt.subplot(131),plt.imshow(ts[i].reshape(x, y))\n",
    "        plt.title('Image '+str(i)), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(132),plt.imshow(tl[i].reshape(x, y))\n",
    "        plt.title('Label'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(133),plt.imshow(ts[i].reshape(x, y)), plt.imshow(tl[i].reshape(x, y), 'binary', interpolation='none', alpha=0.3)\n",
    "        plt.title('Overlay'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "def display_images_labels_predictions (image_file, label_file, pred_file, num_images = 4, image_list = False, random_images = False):\n",
    "    ts = np.load(image_file)\n",
    "    tl = np.load(label_file)\n",
    "    pred = np.load(pred_file)\n",
    "    samples, x, y, z = pred.shape\n",
    "    print (\"samples, max, min \", samples, pred.max(), pred.min())\n",
    "    pred2 = np.round(pred)\n",
    "\n",
    "    ##Print few images wih actual labels and predictions\n",
    "    display_list = []\n",
    "    if image_list == False:\n",
    "        if random_images == True:\n",
    "            display_list = random.sample(range(0, samples), num_images)\n",
    "        else :\n",
    "            display_list = [i for i in range (num_images)]\n",
    "    else:\n",
    "        display_list = image_list\n",
    "\n",
    "    for i in display_list:\n",
    "        f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "        plt.subplot(141),plt.imshow(ts[i].reshape(x, y))\n",
    "        plt.title('Image '+str(i)), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(142),plt.imshow(tl[i].reshape(x, y))\n",
    "        plt.title('Label'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(143),plt.imshow(pred2[i].reshape(x, y))\n",
    "        plt.title('Prediction'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(144),plt.imshow(tl[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "        plt.title('Overlay'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def display_images_predictions (image_file, pred_file,  num_images=4, image_list=False, random_images=False):\n",
    "    ts = np.load(image_file)\n",
    "    pred = np.load(pred_file)\n",
    "    samples, x, y, z = pred.shape\n",
    "    print (\"samples, max, min \", samples, pred.max(), pred.min())\n",
    "    pred2 = np.round(pred)\n",
    "\n",
    "    display_list = []\n",
    "    if image_list == False:\n",
    "        if random_images == True:\n",
    "            display_list = random.sample(range(0, samples), num_images)\n",
    "        else :\n",
    "            display_list = [i for i in range (num_images)]\n",
    "    else:\n",
    "        display_list = image_list\n",
    "\n",
    "    for i in display_list:\n",
    "        f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "        plt.subplot(131),plt.imshow(ts[i].reshape(x, y))\n",
    "        plt.title('Image '+str(i)), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(132),plt.imshow(pred2[i].reshape(x, y))\n",
    "        plt.title('Prediction'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(133),plt.imshow(ts[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.3)\n",
    "        plt.title('Overlay'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_predictions.npy\"\n",
    "perf = compute_performance_statistics( label_file, pred_file)\n",
    "print (perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_predictions.npy\"\n",
    "display_images_labels_predictions (image_file, label_file, pred_file, num_images = 4, random_images = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_labels.npy\"\n",
    "display_images_labels(image_file, label_file, num_images = 4, random_images = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/acdc_1_3_176_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/acdc_1_3_176_test_labels.npy\"\n",
    "display_images_labels(image_file, label_file, num_images = 4, random_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/acdc_1_3_256_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/acdc_1_3_256_test_labels.npy\"\n",
    "display_images_labels(image_file, label_file, num_images = 4, random_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/sunnybrook_1_3_176_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/sunnybrook_1_3_176_test_labels.npy\"\n",
    "display_images_labels(image_file, label_file, num_images = 4, random_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_images.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_predictions.npy\"\n",
    "display_images_predictions (image_file, pred_file, num_images = 4, random_images = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_predictions.npy\"\n",
    "\n",
    "compute_losses (label_file, pred_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_performance.json\"\n",
    "show_performance_statistics(perf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/sunnybrook_1_3_256_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/acdc_diceloss_1_3_176_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_diceloss_1_3_176_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_aug_1_3_176_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_aug_1_3_256_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_predictions.npy\"\n",
    "display_images_labels_predictions (image_file, label_file, pred_file, num_images = 4, random_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = [4, 20, 100, 123,131,184, 219]\n",
    "nopredlist = [127]\n",
    "wrongpredlocation = [204]\n",
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_test_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_predictions.npy\"\n",
    "display_images_labels_predictions (image_file, label_file, pred_file, num_images = 4,image_list = imglist, random_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_train_images.npy\"\n",
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_train_labels.npy\"\n",
    "#pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_176_predictions.npy\"\n",
    "display_images_labels (image_file, label_file,  num_images = 4, random_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_predictions.npy\"\n",
    "perf = compute_performance_statistics( label_file, pred_file)\n",
    "print (perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_1_3_256_test_labels.npy\"\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/baseline/combined_aug_1_3_256_predictions.npy\"\n",
    "perf = compute_performance_statistics( label_file, pred_file)\n",
    "print (perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_drop_1_3_256_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_p = \"/masvol/heartsmart/unet_model/data/baseline/combined_drop_1_3_256_learning_history.json\"\n",
    "plot_accuracy_and_loss(file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
