{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip show tensorflow\n",
    "# ! pip show tensorflow-gpu\n",
    "# !pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/masvol/heartsmart/unet_model\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully imported packages!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import re, sys\n",
    "import fnmatch, shutil, subprocess\n",
    "from IPython.utils import io\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, concatenate, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "#Fix the random seeds for numpy (this is for Keras) and for tensorflow backend to reduce the run-to-run variance\n",
    "from numpy.random import seed\n",
    "seed(100)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\nSuccessfully imported packages!!!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "# #config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# #config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "# #sess.run(yourcommand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.1  # train/test split ratio for Sunnybrook and ACDC data\n",
    "\n",
    "BASE_DIR = \"/opt/output/\"\n",
    "SOURCE = \"sunnybrook\"\n",
    "SB_SOURCE = \"sunnybrook\"\n",
    "ACDC_SOURCE = \"acdc\"\n",
    "TRAIN_IMG_DIR = BASE_DIR + SOURCE + \"/norm/1/3/images/\"\n",
    "TRAIN_LBL_DIR = BASE_DIR + SOURCE + \"/norm/1/3/labels/\"\n",
    "\n",
    "TEST_IMG_DIR = BASE_DIR + SOURCE + \"/norm/1/3/images/\"\n",
    "PRED_RESULT_DIR = BASE_DIR + SOURCE + \"/norm/1/3/images/\"\n",
    "\n",
    "UNET_TRAIN_DIR = BASE_DIR + SOURCE + \"/unet_model/data/\"\n",
    "UNET_MODEL_DIR = BASE_DIR + SOURCE + \"/unet_model/models/\"\n",
    "\n",
    "\n",
    "UNET_TRAIN_DIR = \"/masvol/heartsmart/unet_model/data/\"\n",
    "UNET_MODEL_DIR = \"/masvol/heartsmart/unet_model/models/\"\n",
    "\n",
    "# UNET_TRAIN_DIR = \"/opt/heartsmart/unet_model/data/\"\n",
    "# UNET_MODEL_DIR = \"/opt/heartsmart/unet_model/models/\"\n",
    "\n",
    "DSB_SOURCE = \"dsb\"\n",
    "DSB_TRAIN_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/train/\"\n",
    "DSB_VAL_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/validate/\"\n",
    "DSB_TEST_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/test/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to process and save DSB2 data set into 4d numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#\n",
    "# Methods to process and save DSB2 data set into 4d numpy arrays\n",
    "#\n",
    "################################################\n",
    "def crop_center(img,cropx,cropy):\n",
    "    x,y = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[startx:startx+cropx, starty:starty+cropy]\n",
    "\n",
    "def pad_image(img, img_size):\n",
    "    #print (\"input shape : \", img.shape)\n",
    "    pad_x=0\n",
    "    pad_y=0\n",
    "    x,y = img.shape\n",
    "    if (x<img_size):\n",
    "        pad_x = img_size - x\n",
    "    if (y<img_size):\n",
    "        pad_y = img_size - y\n",
    "    process_img = np.pad(img, pad_width=((pad_x//2, ((pad_x//2) + (pad_x % 2))), (pad_y//2, ((pad_y//2) + (pad_y % 2)))), mode = 'constant', constant_values = 0)\n",
    "    #print (\"output shape : \", process_img.shape)\n",
    "    return process_img\n",
    "\n",
    "\n",
    "def shrink_case(case):\n",
    "    toks = case.split(\"-\")    \n",
    "    def shrink_if_number(x):\n",
    "        try:\n",
    "            cvt = int(x)\n",
    "            return str(cvt)\n",
    "        except ValueError:\n",
    "            return x\n",
    "    return \"-\".join([shrink_if_number(t) for t in toks])\n",
    "\n",
    "class Image_info_map(object):\n",
    "    def __init__(self, ctr_path):\n",
    "        self.ctr_path = ctr_path\n",
    "        #print (ctr_path)\n",
    "        #/opt/output/dsb/norm/1/3/test/1111/sax_13_IM-2680-0008.dcm.npy\n",
    "        match = re.search(r\"/([^/]*)/sax_(\\d+)_IM-(\\d+)-(\\d+).dcm.npy\", ctr_path)\n",
    "        #match = re.search(r\"/([^/]*)/patient\\d+_slice(\\d+)_frame(\\d+)_label_fix.nii.npy\", ctr_path)\n",
    "        try:\n",
    "            self.case = shrink_case(match.group(1))\n",
    "            self.sax_num = int (match.group(2))\n",
    "            self.record = int(match.group(3))\n",
    "            self.img_no = int(match.group(4))\n",
    "        except AttributeError:\n",
    "            #/opt/output/dsb/norm/1/3/train/234/sax_20_IM-3098-0022-0007.dcm.npy\n",
    "            match = re.search(r\"/([^/]*)/sax_(\\d+)_IM-(\\d+)-(\\d+)-(\\d+).dcm.npy\", ctr_path)\n",
    "            self.case = shrink_case(match.group(1))\n",
    "            self.sax_num = int (match.group(2))\n",
    "            self.record = int(match.group(3))\n",
    "            self.img_no = int(match.group(5))\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"<Image info for case %s, record %d image %d>\" % (self.case, self.record, self.img_no)\n",
    "    \n",
    "def get_dsb_image_list2(data_path):\n",
    "    image_list = [os.path.join(dirpath,f) \n",
    "            for files in glob.glob(data_path+\"/*\") \n",
    "            for dirpath, dirname, infiles in os.walk(files) \n",
    "            for f in infiles if f.endswith('dcm.npy')]\n",
    "    \n",
    "    print(\"Number of examples: {:d}\".format(len(image_list)))\n",
    "    #print(\"Shuffle data\")\n",
    "    #np.random.shuffle(image_list)\n",
    "    print (image_list[0], image_list[-1])\n",
    "    \n",
    "    extracted = list(map(Image_info_map, image_list))\n",
    "    print (\"Image 0 :\", extracted[0].case, extracted[0].record, extracted[0].img_no)\n",
    "    print (\"Imae -1 :\", extracted[-1].case, extracted[-1].record, extracted[-1].img_no) \n",
    "    return image_list, extracted\n",
    "\n",
    "def get_dsb_image_list(data_path):\n",
    "    image_list = [os.path.join(data_path,files) \n",
    "            for files in glob.glob(data_path+\"/*\") if files.endswith('dcm.npy')]\n",
    "    \n",
    "    print(\"Number of examples: {:d}\".format(len(image_list)))\n",
    "    #print(\"Shuffle data\")\n",
    "    #np.random.shuffle(image_list)\n",
    "    print (image_list[0], image_list[-1])\n",
    "    \n",
    "    extracted = list(map(Image_info_map, image_list))\n",
    "    print (\"Image 0 :\", extracted[0].case, extracted[0].record, extracted[0].img_no)\n",
    "    print (\"Imae -1 :\", extracted[-1].case, extracted[-1].record, extracted[-1].img_no) \n",
    "    return image_list, extracted\n",
    "\n",
    "def get_dsb_images(data_path, crop_size):\n",
    "    print (\"data path: \", data_path)\n",
    "    img_path_list, extracted_info = get_dsb_image_list(data_path)\n",
    "    img_count = len(img_path_list)\n",
    "    print(\"Processing {:d} images and labels...\".format(img_count))\n",
    "    \n",
    "    imgs , img_path, ext_info = [], [], []\n",
    "    for i in range(img_count):\n",
    "\n",
    "        full_path = img_path_list[i]\n",
    "        img = np.load(full_path)\n",
    "        x,y = img.shape\n",
    "\n",
    "        if x < crop_size or y < crop_size:\n",
    "            #print (\"shapes smaller than crop size\", x, y, crop_size)\n",
    "            img = pad_image(img, crop_size)\n",
    "            #continue\n",
    "        if x > crop_size or y > crop_size:\n",
    "            #print (\"img: \", i, x, y, full_path)\n",
    "            img = crop_center(img,crop_size,crop_size)\n",
    "            \n",
    "        imgs.append(img)\n",
    "        img_path.append(full_path)\n",
    "        ext_info.append(extracted_info[i])\n",
    "\n",
    "        if i % (img_count//3) == 0:\n",
    "            print (full_path)\n",
    "            plt.imshow(img, cmap = 'gray')\n",
    "            plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "            plt.show()\n",
    "\n",
    "            #except IOError:\n",
    "            #    continue\n",
    "    print (\"Final size of image set :\", len(imgs), \"dropped images:\", (img_count - len(imgs)))\n",
    "                \n",
    "    return imgs, img_path, ext_info\n",
    "\n",
    "def convert_images_to_nparray_and_save (imgs, save_file, image_size):\n",
    "    rows = image_size\n",
    "    cols = image_size\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print(\"Converting data to np array, Input size : \",len(imgs))\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgdatas = np.ndarray((len(imgs),rows,cols,1), dtype=np.int)\n",
    "        \n",
    "    for idx in range(len(imgs)):\n",
    "        img = imgs[idx]\n",
    "        img = img_to_array(img)        \n",
    "        try:\n",
    "            imgdatas[i] = img\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        \n",
    "    np.save(save_file, imgdatas)\n",
    "\n",
    "    print (\"Shape of image array : \", imgdatas.shape)\n",
    "    print (\"Max, min, mean values\", imgdatas.max(), imgdatas.min(), imgdatas.mean())\n",
    "    print('Saved data as: ', save_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read DSB3 data set one patient at at time and save them as 4d numpy array \n",
    "\n",
    "patient_record = \"204\"\n",
    "data_path = DSB_TRAIN_IMG_DIR + patient_record\n",
    "image_list, image_path_list, extracted_info = get_dsb_images(data_path, crop_size=176)\n",
    "image_list2, image_path_list2, extracted_info2 = get_dsb_images(data_path, crop_size=256)\n",
    "\n",
    "img_file = UNET_TRAIN_DIR + DSB_SOURCE + patient_record + \"_176.npy\"\n",
    "convert_images_to_nparray_and_save (image_list, img_file, image_size = 176)\n",
    "\n",
    "img_file2 = UNET_TRAIN_DIR + DSB_SOURCE + patient_record + \"_256.npy\"\n",
    "convert_images_to_nparray_and_save (image_list2, img_file2, image_size = 256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Read DSB3 data set one patient at at time and save them as 4d numpy array \n",
    "# for record in range (300, 311) :\n",
    "#     patient_record = str(record)\n",
    "#     print (patient_record)\n",
    "#     data_path = DSB_TRAIN_IMG_DIR + patient_record\n",
    "#     image_list, image_path_list, extracted_info = get_dsb_images(data_path, crop_size=176)\n",
    "#     image_list2, image_path_list2, extracted_info2 = get_dsb_images(data_path, crop_size=256)\n",
    "\n",
    "#     img_file = UNET_TRAIN_DIR + DSB_SOURCE + patient_record + \"_176.npy\"\n",
    "#     convert_images_to_nparray_and_save (image_list, img_file, image_size = 176)\n",
    "\n",
    "#     img_file2 = UNET_TRAIN_DIR + DSB_SOURCE + patient_record + \"_256.npy\"\n",
    "#     convert_images_to_nparray_and_save (image_list2, img_file2, image_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here  if training/test data are already stored in unet_model/data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to load 4d np array for images from ./data directory, perform pixel normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#\n",
    "# Methods to load 4d np array for images from ./data directory\n",
    "# 4D tensor with shape: (samples, rows, cols, channels=1)\n",
    "#\n",
    "#########################################\n",
    "\n",
    "def load_images_and_labels(data):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images and labels...')\n",
    "    print('-'*30)\n",
    "    imgfile = data[\"images\"]\n",
    "    labelfile = data[\"labels\"]\n",
    "    print (\"Loading files : \", imgfile, labelfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    lb = np.load(labelfile)\n",
    "    images = im.astype('float32')\n",
    "    labels = lb.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    print(\"shape, max, min, mean of labels :\", labels.shape, labels.max(), labels.min(), labels.mean())\n",
    "    return images2, labels\n",
    "\n",
    "\n",
    "\n",
    "def load_images(imgfile):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images ...')\n",
    "    print('-'*30)\n",
    "    print (\"Loading files : \", imgfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    images = im.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    return images2\n",
    "\n",
    "def combine_acdc_sunnybrook_data_176():\n",
    "    acdc_train_data = {}\n",
    "    acdc_train_data[\"images\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_176_train_images.npy\"\n",
    "    acdc_train_data[\"labels\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_176_train_labels.npy\"\n",
    "\n",
    "    acdc_train_img, acdc_train_lbl = load_images_and_labels(acdc_train_data)\n",
    "\n",
    "    acdc_test_data = {}\n",
    "    acdc_test_data[\"images\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_176_test_images.npy\"\n",
    "    acdc_test_data[\"labels\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_176_test_labels.npy\"\n",
    "\n",
    "    acdc_test_img, acdc_test_lbl = load_images_and_labels(acdc_test_data)\n",
    "\n",
    "    sb_train_data = {}\n",
    "    sb_train_data[\"images\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_176_train_images.npy\"\n",
    "    sb_train_data[\"labels\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_176_train_labels.npy\"\n",
    "    sb_train_img, sb_train_lbl = load_images_and_labels(sb_train_data)\n",
    "\n",
    "    sb_test_data = {}\n",
    "    sb_test_data[\"images\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_176_test_images.npy\"\n",
    "    sb_test_data[\"labels\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_176_test_labels.npy\"\n",
    "    sb_test_img, sb_test_lbl = load_images_and_labels(sb_test_data)\n",
    "\n",
    "    combined_train_img = np.concatenate((acdc_train_img, sb_train_img), axis=0)\n",
    "    combined_train_lbl = np.concatenate((acdc_train_lbl, sb_train_lbl), axis=0)\n",
    "\n",
    "    combined_test_img = np.concatenate((acdc_test_img, sb_test_img), axis=0)\n",
    "    combined_test_lbl = np.concatenate((acdc_test_lbl, sb_test_lbl), axis=0)\n",
    "    print (combined_train_img.shape, combined_train_lbl.shape,combined_test_img.shape,combined_test_lbl.shape)\n",
    "    print (\"Saving combined files.......\")\n",
    "\n",
    "    tr_img_file = UNET_TRAIN_DIR + \"combined_176_train_images.npy\"\n",
    "    tr_lbl_file = UNET_TRAIN_DIR + \"combined_176_train_labels.npy\"\n",
    "    tst_img_file = UNET_TRAIN_DIR + \"combined_176_test_images.npy\"\n",
    "    tst_lbl_file = UNET_TRAIN_DIR + \"combined_176_test_labels.npy\"\n",
    "\n",
    "    np.save(tr_img_file, combined_train_img)\n",
    "    np.save(tr_lbl_file, combined_train_lbl)\n",
    "    np.save(tst_img_file, combined_test_img)\n",
    "    np.save(tst_lbl_file, combined_test_lbl)\n",
    "    \n",
    "def combine_acdc_sunnybrook_data_256():\n",
    "    acdc_train_data = {}\n",
    "    acdc_train_data[\"images\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_256_train_images.npy\"\n",
    "    acdc_train_data[\"labels\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_256_train_labels.npy\"\n",
    "\n",
    "    acdc_train_img, acdc_train_lbl = load_images_and_labels(acdc_train_data)\n",
    "\n",
    "    acdc_test_data = {}\n",
    "    acdc_test_data[\"images\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_256_test_images.npy\"\n",
    "    acdc_test_data[\"labels\"] = UNET_TRAIN_DIR + ACDC_SOURCE + \"_256_test_labels.npy\"\n",
    "\n",
    "    acdc_test_img, acdc_test_lbl = load_images_and_labels(acdc_test_data)\n",
    "\n",
    "    sb_train_data = {}\n",
    "    sb_train_data[\"images\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_256_train_images.npy\"\n",
    "    sb_train_data[\"labels\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_256_train_labels.npy\"\n",
    "    sb_train_img, sb_train_lbl = load_images_and_labels(sb_train_data)\n",
    "\n",
    "    sb_test_data = {}\n",
    "    sb_test_data[\"images\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_256_test_images.npy\"\n",
    "    sb_test_data[\"labels\"] = UNET_TRAIN_DIR + SB_SOURCE + \"_256_test_labels.npy\"\n",
    "    sb_test_img, sb_test_lbl = load_images_and_labels(sb_test_data)\n",
    "\n",
    "    combined_train_img = np.concatenate((acdc_train_img, sb_train_img), axis=0)\n",
    "    combined_train_lbl = np.concatenate((acdc_train_lbl, sb_train_lbl), axis=0)\n",
    "\n",
    "    combined_test_img = np.concatenate((acdc_test_img, sb_test_img), axis=0)\n",
    "    combined_test_lbl = np.concatenate((acdc_test_lbl, sb_test_lbl), axis=0)\n",
    "    print (combined_train_img.shape, combined_train_lbl.shape,combined_test_img.shape,combined_test_lbl.shape)\n",
    "    print (\"Saving combined files.......\")\n",
    "\n",
    "    tr_img_file = UNET_TRAIN_DIR + \"combined_256_train_images.npy\"\n",
    "    tr_lbl_file = UNET_TRAIN_DIR + \"combined_256_train_labels.npy\"\n",
    "    tst_img_file = UNET_TRAIN_DIR + \"combined_256_test_images.npy\"\n",
    "    tst_lbl_file = UNET_TRAIN_DIR + \"combined_256_test_labels.npy\"\n",
    "\n",
    "    np.save(tr_img_file, combined_train_img)\n",
    "    np.save(tr_lbl_file, combined_train_lbl)\n",
    "    np.save(tst_img_file, combined_test_img)\n",
    "    np.save(tst_lbl_file, combined_test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine_acdc_sunnybrook_data_176()\n",
    "#combine_acdc_sunnybrook_data_256()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#\n",
    "# Loss functions\n",
    "#\n",
    "#########################################\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_dice_coeff(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = 1 - weighted_dice_coeff(y_true, y_pred, weight)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                          (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "\n",
    "\n",
    "def my_bce_loss(y_true, y_pred):\n",
    "#     y_true = K.cast(y_true, 'float32')\n",
    "#     y_pred = K.cast(y_pred, 'float32')\n",
    " \n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = (y_true * K.log(y_pred[i])) + ((1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean(loss, axis=-1)        \n",
    "    #return K.sum(loss)\n",
    "# def my_bce_loss(y_true, y_pred):\n",
    "#     y_true_f = y_true.flatten()\n",
    "#     y_pred_f = y_pred.flatten()\n",
    "    \n",
    "#     # avoiding overflow\n",
    "#     epsilon = 1e-7\n",
    "#     y_pred_f[y_pred_f<=0.] = epsilon\n",
    "#     y_pred_f[y_pred_f>=1.] = 1. -epsilon\n",
    "#     #y_pred = K.clip(y_pred_f, epsilon, 1. - epsilon)\n",
    "#     #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "#     result = []\n",
    "#     result.append([y_true[i] * math.log(y_pred[i]) + (1 - y_true[i]) * math.log(1 - y_pred[i]) \\\n",
    "#                    for i in range(len(y_pred))])\n",
    "#     return np.mean(result)\n",
    "\n",
    "\n",
    "\n",
    "def penalized_bce_loss(weight):\n",
    "    def weighted_bce_loss(y_true, y_pred):\n",
    "        # avoiding overflow\n",
    "        epsilon = 1e-7\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "        loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "        return K.sum(loss) / K.sum(weight)\n",
    "    return weighted_bce_loss\n",
    "\n",
    "def penalized_bce_loss2(weight):\n",
    "    def weighted_bce_loss(y_true, y_pred):\n",
    "        # avoiding overflow\n",
    "        epsilon = 1e-7\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "        loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                              (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "        return K.sum(loss) / K.sum(weight)\n",
    "    return weighted_bce_loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + (1 - weighted_dice_coeff(y_true, y_pred, weight))\n",
    "    return loss\n",
    "\n",
    "########################################\n",
    "# \n",
    "# Method to evaluate the performance of u-net by computing, logloss, precision, reccall, f1score etc\n",
    "#\n",
    "#################################################\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    y_pred_r = np.round(y_pred_f)\n",
    "\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred_f[y_pred_f<=0.] = epsilon\n",
    "    y_pred_f[y_pred_f>=1.] = 1. -epsilon\n",
    "    #y_pred = K.clip(y_pred_f, epsilon, 1. - epsilon)\n",
    "    #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    perf = {}\n",
    "    result = []\n",
    "    result2 = []\n",
    "    \n",
    "    true_p = 0.0\n",
    "    true_n = 0.0\n",
    "    false_p = 0.0\n",
    "    false_n = 0.0\n",
    "    for i in range (len(y_pred_f)):\n",
    "        result.append (y_true_f[i] * np.log(y_pred_f[i]) + (1 - y_true_f[i]) * np.log(1 - y_pred_f[i]))\n",
    "        result2.append (y_true_f[i] * np.log2(y_pred_f[i]) + (1 - y_true_f[i]) * np.log2(1 - y_pred_f[i]))\n",
    "\n",
    "        if (y_pred_r[i] == 0 and y_true_f[i] == 0):\n",
    "            true_n += 1.\n",
    "        elif (y_pred_r[i] == 0 and y_true_f[i] == 1):\n",
    "            false_n += 1.\n",
    "        elif (y_pred_r[i] == 1 and y_true_f[i] == 1):\n",
    "            true_p += 1.\n",
    "        elif (y_pred_r[i] == 1 and y_true_f[i] == 0):\n",
    "            false_p += 1.\n",
    "            \n",
    "    loss = np.mean(result)\n",
    "    loss2 = np.mean(result2)\n",
    "    accuracy = (true_p + true_n)/(true_p + true_n + false_p + false_n)\n",
    "    precision = true_p/(true_p + false_p)\n",
    "    recall    = true_p/(true_p + false_n)\n",
    "    f1_score = (2 * precision * recall)/(precision+recall)\n",
    "    \n",
    "    print (len(result), sum(result))\n",
    "    print (\"true_pos : %d, false_pos : %d, true_neg  %d, false_neg : %d\"%(true_p, false_p, true_n, false_n))\n",
    "    print (\"accuracy : %f, precision : %f, recall  %f, f1_score : %f\"%(accuracy, precision, recall, f1_score))\n",
    "    print (\"logloss : %f, log2loss : %f \"%(loss, loss2))\n",
    "    perf[\"logloss\"] = loss\n",
    "    perf[\"log2loss\"] = loss2\n",
    "    perf[\"true_positive\"] = true_p\n",
    "    perf[\"false_positive\"] = false_p\n",
    "    perf[\"true_negative\"] = true_n\n",
    "    perf[\"false_negative\"] = false_n\n",
    "    perf[\"accuracy\"] = accuracy\n",
    "    perf[\"precision\"] = precision\n",
    "    perf[\"recall\"] = recall\n",
    "    perf[\"f1_score\"] = f1_score\n",
    "    \n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#\n",
    "# Unet models\n",
    "#\n",
    "################################\n",
    "\n",
    "class myUnet(object):\n",
    "\n",
    "    def __init__(self, image_size = 256, model_type = \"small\"):\n",
    "        self.img_rows = image_size\n",
    "        self.img_cols = image_size\n",
    "        self.model_type = model_type\n",
    "        if model_type == \"small\":\n",
    "            self.build_unet_small()\n",
    "        elif model_type == \"large\":\n",
    "            self.build_unet()\n",
    "        elif model_type == \"large2\":\n",
    "            self.build_unet()\n",
    "        else :\n",
    "            print (\"Specify valid model_type (small, large, large2)\")\n",
    "            return\n",
    "\n",
    "    def load_data(self, train_data, test_data):\n",
    "        print('-'*30)\n",
    "        print(\"loading data\")\n",
    "        self.train_images, self.train_labels = load_images_and_labels(train_data)\n",
    "        self.test_images, self.test_labels = load_images_and_labels(test_data)       \n",
    "        print(\"loading data done\")\n",
    "        print('-'*30)\n",
    "\n",
    "    def build_unet_small(self):\n",
    "        \n",
    "        '''\n",
    "        Input shape\n",
    "        4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' \n",
    "        or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last' (default format).\n",
    "        \n",
    "        Output shape\n",
    "        4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or \n",
    "        4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format='channels_last'. \n",
    "        rows and cols values might have changed due to padding.\n",
    "        \n",
    "        He_normal initialization: It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) \n",
    "        where  fan_in is the number of input units in the weight tensor.\n",
    "        '''\n",
    "\n",
    "        print('-'*30)\n",
    "        print (\"Building smaller version of U-net model\")\n",
    "        print('-'*30)\n",
    "        \n",
    "        inputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "        conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "        conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "        conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        print (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "        conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        drop4 = Dropout(0.2)(conv4)\n",
    "        \n",
    "        up5 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop4))\n",
    "        merge5 = concatenate([conv3,up5], axis = 3)\n",
    "        conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
    "        conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        \n",
    "        up6 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "        merge6 = concatenate([conv2,up6], axis = 3)\n",
    "        conv6 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = concatenate([conv1,up7], axis = 3)\n",
    "        conv7 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        conv8 = Conv2D(1, 1, activation = 'sigmoid')(conv7)\n",
    "\n",
    "        self.model = Model(input = inputs, output = conv8)\n",
    "\n",
    "        self.model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])\n",
    "        #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    def build_unet(self):\n",
    "        \n",
    "        '''\n",
    "        Input shape\n",
    "        4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' \n",
    "        or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last' (default format).\n",
    "        \n",
    "        Output shape\n",
    "        4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or \n",
    "        4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format='channels_last'. \n",
    "        rows and cols values might have changed due to padding.\n",
    "        '''\n",
    "        print('-'*30)\n",
    "        print (\"Building U-net model\")\n",
    "        print('-'*30)\n",
    "        \n",
    "        inputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        print (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        #drop4 = Dropout(0.5)(conv4)\n",
    "        drop4 = conv4\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        merge6 = concatenate([drop4,up6], axis = 3)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = concatenate([conv3,up7], axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = concatenate([conv2,up8], axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = concatenate([conv1,up9], axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "        self.model = Model(input = inputs, output = conv10)\n",
    "\n",
    "        #self.model.compile(optimizer=RMSprop(lr=0.0001), loss=penalized_bce_loss(weight=0.08), metrics=['binary_accuracy'])\n",
    "        #self.model.compile(optimizer=RMSprop(lr=0.0001), loss=dice_loss, metrics=[dice_coeff])\n",
    "\n",
    "        #metrics=['accuracy'] calculates accuracy automatically from cost function. So using binary_crossentropy shows binary \n",
    "        #accuracy, not categorical accuracy.Using categorical_crossentropy automatically switches to categorical accuracy\n",
    "        #One can get both categorical and binary accuracy by using metrics=['binary_accuracy', 'categorical_accuracy']\n",
    "        \n",
    "        self.model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = [dice_coeff])\n",
    "        #self.model.compile(optimizer = Adam(lr = 1e-4), loss = my_bce_loss, metrics = ['binary_accuracy'])\n",
    "    \n",
    "    def load_pretrained_weights(self, model_file):\n",
    "        self.model_file = model_file\n",
    "        print('-'*30)\n",
    "        print('Loading pre-trained weights...')\n",
    "        self.model.load_weights(self.model_file)\n",
    "        print('-'*30)   \n",
    "\n",
    "    def predict(self, test_image_array, test_label_array =\"none\"):\n",
    "        self.test_images = test_image_array\n",
    "        self.test_labels = test_label_array\n",
    "        print('-'*30)\n",
    "        print('predict test data....')\n",
    "        self.predictions = self.model.predict(self.test_images, batch_size=1, verbose=1)\n",
    "        print('-'*30)\n",
    "        print('-'*30)\n",
    "        if self.test_labels != \"none\" :\n",
    "            scores = self.model.evaluate (self.predictions, self.test_labels, batch_size=4)\n",
    "            print (\"Prediction Scores before rounding\", scores)\n",
    "\n",
    "            pred2 = np.round(self.predictions)\n",
    "            scores = self.model.evaluate (pred2,  self.test_labels, batch_size=4)\n",
    "            print (\"Prediction Scores after rounding\", scores)\n",
    "\n",
    "    def train_and_predict(self, model_file, batch_size = 4, nb_epoch = 10, augmentation = False): \n",
    "        self.model_file = model_file #path to save the weights with best model\n",
    "        model_checkpoint = ModelCheckpoint(self.model_file, monitor='loss',verbose=1, save_best_only=True)\n",
    "        \n",
    "        if augmentation == True :\n",
    "            sample_size, x_val, y_val, ax = self.train_images.shape\n",
    "            #save original train images\n",
    "            self.original_train_images = self.train_images\n",
    "            self.original_train_labels = self.train_labels\n",
    "            # we create two instances with the same arguments\n",
    "            data_gen_args = dict(\n",
    "                                 rotation_range=90.,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1,\n",
    "                                 zoom_range=0.2)\n",
    "\n",
    "            image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            \n",
    "            # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "            seed = 1\n",
    "            image_generator = image_datagen.flow(self.train_images, y=None, seed = seed, batch_size=sample_size)\n",
    "            mask_generator = mask_datagen.flow(self.train_labels,  y=None, seed = seed, batch_size=sample_size)\n",
    "            train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "            MAX_AUG=3\n",
    "            print('-'*30)\n",
    "            print('Augmenting training data...')\n",
    "            augmentation_round = 0\n",
    "            for img_tr, mask_tr in train_generator:\n",
    "                    self.train_images = np.concatenate((self.train_images, img_tr), axis=0)\n",
    "                    self.train_labels = np.concatenate((self.train_labels, mask_tr), axis=0)\n",
    "                    print (\"Augmentation round: \", augmentation_round+1, img_tr.shape, self.train_images.shape, self.train_labels.shape)\n",
    "                    augmentation_round += 1\n",
    "                    if (augmentation_round == MAX_AUG):\n",
    "                          break\n",
    "                            \n",
    "        print('-'*30)\n",
    "        print('Fitting model...')\n",
    "        print('-'*30)\n",
    "        #class_weight: Optional dictionary mapping class indices (integers) to a weight (float) value, \n",
    "        #used for weighting the loss function (during training only). This can be useful to tell the model \n",
    "        #to \"pay more attention\" to samples from an under-represented class.\n",
    "        # used balanced class weights .... n_samples / (n_classes * np.bincount(y))\n",
    "        tl2 = self.train_labels.flatten().astype('int32')\n",
    "        weights = (tl2.shape[0])/(2*np.bincount(tl2))\n",
    "        class_weights = {}\n",
    "        class_weights[0] = weights[0]\n",
    "        class_weights[1] = weights[1]\n",
    "        print (\"class weights\", class_weights)\n",
    "        \n",
    "        self.history = self.model.fit(self.train_images, self.train_labels, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "        print('-'*30)\n",
    "        print('predict test data....')\n",
    "        self.predictions = self.model.predict(self.test_images, batch_size=1, verbose=1)\n",
    "        scores = self.model.evaluate (self.predictions, self.test_labels, batch_size=4)\n",
    "        print (\"Prediction Scores\", scores)\n",
    "        pred_file = \"predictions_sk2.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        np.save(pred_file, self.predictions)\n",
    "        print('-'*30)\n",
    "        \n",
    "\n",
    "    def train_with_augmentation2(self, model_file, batch_size = 4, nb_epoch = 10 ):\n",
    "\n",
    "        sample_size, x_val, y_val, ax = self.train_images.shape\n",
    "\n",
    "        model_file = UNET_MODEL_DIR+'unet_aug2.hdf5' #path to save the weights with best model\n",
    "        model_checkpoint = ModelCheckpoint(model_file, monitor='loss',verbose=1, save_best_only=True)\n",
    "        \n",
    "        # we create two instances with the same arguments\n",
    "        data_gen_args = dict(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=90.,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2)\n",
    "        \n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        seed = 1\n",
    "        image_datagen.fit(self.train_images, augment=True, seed=seed)\n",
    "        mask_datagen.fit(self.train_labels, augment=True, seed=seed)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        seed = 1\n",
    "        image_generator = image_datagen.flow(self.train_images, y=None, seed = seed, batch_size=sample_size)\n",
    "        mask_generator = mask_datagen.flow(self.train_labels,  y=None, seed = seed, batch_size=sample_size)\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "        \n",
    "        print('-'*30)\n",
    "        print('Fitting model...')\n",
    "        \n",
    "        self.model.fit(self.train_images, self.train_labels, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "        \n",
    "        MAX_AUG=2\n",
    "        augmentation_round = 0\n",
    "        for img_tr, mask_tr in train_generator:\n",
    "                print (\"Augmentation round: \", augmentation_round+1, img_tr.shape)\n",
    "                s, x1, y1, p = img_tr.shape\n",
    "                self.model.fit(img_tr, mask_tr, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "                augmentation_round += 1\n",
    "                if (augmentation_round == MAX_AUG):\n",
    "                      break\n",
    "            \n",
    "        \n",
    "        print('-'*30)\n",
    "        print('Run Predictions on test data')\n",
    "        self.predictions = self.model.predict(self.test_images, batch_size=1, verbose=1)\n",
    "        \n",
    "        pred_file = \"predictions_aug_sk1.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        np.save(pred_file, self.predictions)\n",
    "        print('-'*30)\n",
    "        \n",
    "    def save_img(self):\n",
    "        pred_file = \"predictions.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load(pred_file)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"./%d.jpg\"%(i))\n",
    "\n",
    "    def display_ytrue_ypred (self, num_images = 4, random_images = False, evaluate= False):\n",
    "        # if there are no test labels then just display the predictions\n",
    "        if self.test_labels == \"none\":\n",
    "            self.display_ypred (num_images = num_images, random_images = False)\n",
    "            return\n",
    "        \n",
    "        ts , tl= self.test_images, self.test_labels\n",
    "        pred = self.predictions\n",
    "        samples, x, y, z = pred.shape\n",
    "        print (\"samples, max, min \", samples, pred.max(), pred.min())\n",
    "        pred2 = np.round(pred)\n",
    "        if (evaluate == True) :\n",
    "            scores = self.model.evaluate (pred, tl, batch_size=1)\n",
    "            print (\"Prediction Scores\", scores)\n",
    "\n",
    "            scores = self.model.evaluate (pred2, tl, batch_size=1)\n",
    "            print (\"Prediction Scores after rounding\", scores)\n",
    "        ##Print few images wih actual labels and predictions\n",
    "        display_list = []\n",
    "\n",
    "        if random_images == True:\n",
    "            display_list = random.sample(range(0, samples), num_images)\n",
    "        else :\n",
    "            display_list = [i for i in range (num_images)]\n",
    "            \n",
    "        for i in display_list:\n",
    "            f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "            plt.subplot(141),plt.imshow(ts[i].reshape(x, y))\n",
    "            plt.title('test image '+str(i)), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(142),plt.imshow(tl[i].reshape(x, y))\n",
    "            plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(143),plt.imshow(pred2[i].reshape(x, y))\n",
    "            plt.title('pred label'), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(144),plt.imshow(tl[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "            plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "            plt.show()\n",
    "            \n",
    "#             f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "#             plt.subplot(131),plt.imshow(ts[i].reshape(x, y))\n",
    "#             plt.title('test Image'+ str(i)), plt.xticks([]), plt.yticks([])\n",
    "#             plt.subplot(132),plt.imshow(tl[i].reshape(x, y))\n",
    "#             plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "#             plt.subplot(133),plt.imshow(pred[i].reshape(x, y))\n",
    "#             plt.title('Predicted mask'), plt.xticks([]), plt.yticks([])\n",
    "#             plt.show()\n",
    "    \n",
    "    \n",
    "    def display_ypred (self, num_images = 4, random_images = False):\n",
    "        ts = self.test_images\n",
    "        pred = self.predictions\n",
    "        samples, x, y, z = pred.shape\n",
    "        print (\"samples, max, min \", samples, pred.max(), pred.min())\n",
    "        pred2 = np.round(pred)\n",
    "\n",
    "        display_list = []\n",
    "\n",
    "        if random_images == True:\n",
    "            display_list = random.sample(range(0, samples), num_images)\n",
    "        else :\n",
    "            display_list = [i for i in range (num_images)]\n",
    "\n",
    "        for i in display_list:\n",
    "            f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "            plt.subplot(131),plt.imshow(ts[i].reshape(x, y))\n",
    "            plt.title('test image '+str(i)), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(132),plt.imshow(pred2[i].reshape(x, y))\n",
    "            plt.title('prediction'), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(133),plt.imshow(ts[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.3)\n",
    "            plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "            plt.show()\n",
    "        \n",
    "    def plot_accuracy_and_loss(self):\n",
    "        # list all data in history\n",
    "        print(self.history.history.keys())\n",
    "        history = self.history\n",
    "        print (\"First and final values of learning curve\")\n",
    "        for key in history.history:\n",
    "            print (key, history.history[key][0], history.history[key][-1])\n",
    "        # summarize history for accuracy\n",
    "        if 'dice_coeff' in self.history.history.keys():\n",
    "            plt.plot(history.history['dice_coeff'])\n",
    "            plt.plot(history.history['val_dice_coeff'])\n",
    "            plt.title('model accuracy(dice_coeff)')\n",
    "        elif 'val_acc' in self.history.history.keys():\n",
    "            plt.plot(history.history['acc'])\n",
    "            plt.plot(history.history['val_acc'])\n",
    "            plt.title('model accuracy')\n",
    "        elif 'categorical_accuracy' in self.history.history.keys():\n",
    "            plt.plot(history.history['categorical_accuracy'])\n",
    "            plt.plot(history.history['val_categorical_accuracy'])\n",
    "            plt.title('categorical_accuracy')\n",
    "        elif 'binary_accuracy' in self.history.history.keys():\n",
    "            plt.plot(history.history['binary_accuracy'])\n",
    "            plt.plot(history.history['val_binary_accuracy'])\n",
    "            plt.title('binary_accuracy')\n",
    "        else : \n",
    "            print (\"new loss function, not in the list\")\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Method to create a U-net model and train it\n",
    "# Create a U-Net model, train the model and run the predictions and save the trained weights and predictions\n",
    "#\n",
    "##########################\n",
    "# /masvol/heartsmart/unet_model/data/sunnybrook_176_train_images.npy \n",
    "# /masvol/heartsmart/unet_model/data/sunnybrook_176_train_images.npy \n",
    "# /masvol/heartsmart/unet_model/data/sunnybrook_176_train_labels.npy\n",
    "\n",
    "def train_unet_model (source_path, model_path, source, image_size, batch_size, epochs, augmentation = False, model_summary = False):\n",
    "    source_list = [\"sunnybrook\", \"acdc\", \"combined\"]\n",
    "    if source not in source_list:\n",
    "        print (\"source \", source, \" is not in list \", source_list)\n",
    "        return \n",
    "    size_str = str(image_size)\n",
    "    \n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    train_data[\"images\"] = source_path + source + \"_\" + size_str + \"_train_images.npy\"\n",
    "    train_data[\"labels\"] = source_path + source + \"_\" + size_str+ \"_train_labels.npy\"\n",
    "    test_data[\"images\"] = source_path + source + \"_\" + size_str + \"_test_images.npy\"\n",
    "    test_data[\"labels\"] = source_path + source + \"_\" + size_str + \"_test_labels.npy\"\n",
    "\n",
    "    model_file = model_path + source + \"_\" + size_str + '.hdf5'\n",
    "    \n",
    "    if not os.path.exists(source_path):\n",
    "        print (\"source path does not exist \", source_path)\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print (\"creating dir \", model_path)\n",
    "        os.makedirs(model_path)\n",
    "            \n",
    "    # get the u-net model and load train and test data\n",
    "    myunet = myUnet(image_size = image_size, model_type = \"large\")\n",
    "    myunet.load_data (train_data, test_data)\n",
    "\n",
    "    if (model_summary == True):\n",
    "        myunet.model.summary()\n",
    "        \n",
    "    res = myunet.train_and_predict(model_file, batch_size = batch_size, nb_epoch = epochs, augmentation = augmentation)\n",
    "    \n",
    "#     if (augmentation == True) :\n",
    "#         res = myunet.train_with_augmentation(model_file, batch_size = batch_size, nb_epoch = epochs)\n",
    "#     else :\n",
    "#         res = myunet.train_and_predict(model_file, batch_size = batch_size, nb_epoch = epochs)\n",
    "        \n",
    "    return myunet\n",
    "        \n",
    "    #sess.run(myunet.train_and_predict(model_file, batch_size = 4, nb_epoch = 5))\n",
    "    #res = myunet.train_and_predict(model_file, batch_size = 4, nb_epoch = 20)\n",
    "    #res = myunet.train_with_augmentation(model, batch_size = 4, nb_epoch = 10)\n",
    "    \n",
    "############\n",
    "#Method to train all models \n",
    "########################\n",
    "def train_all_models( batch_size = 4, epochs = 10, augmentation = False):\n",
    "    source_list = [\"sunnybrook\", \"acdc\", \"combined\"]\n",
    "    img_size_list = [176, 256]\n",
    "    for mysource in source_list :\n",
    "        for img_size in img_size_list :\n",
    "            mymodel = train_unet_model (source_path = UNET_TRAIN_DIR, model_path = UNET_MODEL_DIR, source = mysource, \\\n",
    "                         image_size= img_size, batch_size= batch_size, epochs= epochs, augmentation= augmentation, model_summary= False)\n",
    "\n",
    "            mymodel.plot_accuracy_and_loss()\n",
    "            mymodel.display_ytrue_ypred(num_images = 4, random_images = True, evaluate = True)\n",
    "            \n",
    "############\n",
    "#Method to train all models \n",
    "########################            \n",
    "def train_one_model(source, image_size, batch_size = 4, epochs = 10, augmentation = False):\n",
    "    source_list = [\"sunnybrook\", \"acdc\", \"combined\"]\n",
    "    img_size_list = [176, 256]\n",
    "    if source not in source_list:\n",
    "        print (\"source \", source, \" is not in list \", source_list)\n",
    "        return\n",
    "    if image_size not in img_size_list:\n",
    "        print (\"image size %d is not supported\"%image_size)\n",
    "        return \n",
    "\n",
    "    mymodel = train_unet_model (source_path = UNET_TRAIN_DIR, model_path = UNET_MODEL_DIR, source = source, \\\n",
    "                 image_size= image_size, batch_size= batch_size, epochs= epochs, augmentation= augmentation, model_summary= False)\n",
    "\n",
    "    mymodel.plot_accuracy_and_loss()\n",
    "    mymodel.display_ytrue_ypred(num_images = 4, random_images = True, evaluate = True)\n",
    "    return mymodel\n",
    "\n",
    "####################\n",
    "# Prediction using pre-trained weights\n",
    "###################\n",
    "\n",
    "def predict_with_pretrained_weights(model_file, image_size, test_image_file, test_label_file = \"none\"):\n",
    "    img_size_list = [176, 256]\n",
    "    if image_size not in img_size_list:\n",
    "        print (\"image size %d is not supported\"%image_size)\n",
    "        return \n",
    "    \n",
    "    size_str = str(image_size)\n",
    "    \n",
    "    test_data = {}\n",
    "    test_data[\"images\"] = test_image_file\n",
    "    test_data[\"labels\"] = test_label_file\n",
    "\n",
    "    model_file = model_file\n",
    "\n",
    "    print('-'*30)\n",
    "    print (\"Get Test images and labels...\")\n",
    "    if test_label_file == \"none\": \n",
    "        ts = load_images(test_image_file)\n",
    "        tl = \"none\"\n",
    "    else :\n",
    "        ts , tl= load_images_and_labels(test_data)\n",
    "\n",
    "    print('-'*30)\n",
    "    print (\"Creating U-net model...\")\n",
    "    myunet = myUnet(image_size = image_size, model_type = \"large\")\n",
    "    print('-'*30)\n",
    "    print (\"Loading the pre-trained weights...\")\n",
    "    myunet.load_pretrained_weights(model_file)\n",
    "    print('-'*30)\n",
    "\n",
    "    print('Run predictions...')\n",
    "    myunet.predict(test_image_array = ts, test_label_array = tl)\n",
    "    print('-'*30)\n",
    "\n",
    "    myunet.display_ytrue_ypred(num_images = 4, random_images = False, evaluate = False)\n",
    "    return myunet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Building U-net model\n",
      "------------------------------\n",
      "conv1 shape: (?, 256, 256, 64)\n",
      "conv1 shape: (?, 256, 256, 64)\n",
      "pool1 shape: (?, 128, 128, 64)\n",
      "conv2 shape: (?, 128, 128, 128)\n",
      "conv2 shape: (?, 128, 128, 128)\n",
      "pool2 shape: (?, 64, 64, 128)\n",
      "conv3 shape: (?, 64, 64, 256)\n",
      "conv3 shape: (?, 64, 64, 256)\n",
      "pool3 shape: (?, 32, 32, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:172: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "loading data\n",
      "------------------------------\n",
      "load np arrays of images and labels...\n",
      "------------------------------\n",
      "Loading files :  /masvol/heartsmart/unet_model/data/sunnybrook_256_train_images.npy /masvol/heartsmart/unet_model/data/sunnybrook_256_train_labels.npy\n",
      "shape, max, min, mean of original image set: (725, 256, 256, 1) 3017.0 0.0 110.88747\n",
      "shape, max, min, mean after normalization  : (725, 256, 256, 1) 1.0 0.0 0.12588005\n",
      "shape, max, min, mean of labels : (725, 256, 256, 1) 1.0 0.0 0.031162761\n",
      "------------------------------\n",
      "load np arrays of images and labels...\n",
      "------------------------------\n",
      "Loading files :  /masvol/heartsmart/unet_model/data/sunnybrook_256_test_images.npy /masvol/heartsmart/unet_model/data/sunnybrook_256_test_labels.npy\n",
      "shape, max, min, mean of original image set: (80, 256, 256, 1) 3071.0 0.0 114.81773\n",
      "shape, max, min, mean after normalization  : (80, 256, 256, 1) 1.0 0.0 0.12337347\n",
      "shape, max, min, mean of labels : (80, 256, 256, 1) 1.0 0.0 0.030335044\n",
      "loading data done\n",
      "------------------------------\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "class weights {0: 0.5160825578289636, 1: 16.044790987772302}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`class_weight` not supported for 3+ dimensional targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3249e1edc5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sunnybrook\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-a89eca8dd6b8>\u001b[0m in \u001b[0;36mtrain_one_model\u001b[0;34m(source, image_size, batch_size, epochs, augmentation)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmymodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_unet_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNET_TRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNET_MODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_accuracy_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a89eca8dd6b8>\u001b[0m in \u001b[0;36mtrain_unet_model\u001b[0;34m(source_path, model_path, source, image_size, batch_size, epochs, augmentation, model_summary)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmyunet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyunet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#     if (augmentation == True) :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-70cc8d4c75ef>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m(self, model_file, batch_size, nb_epoch, augmentation)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"class weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1486\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1486\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             raise ValueError('`class_weight` not supported for '\n\u001b[0m\u001b[1;32m    518\u001b[0m                              '3+ dimensional targets.')\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `class_weight` not supported for 3+ dimensional targets."
     ]
    }
   ],
   "source": [
    "# Train a model by specifying training source , image size , training parameters, \n",
    "\n",
    "\n",
    "test_model = train_one_model(source = \"sunnybrook\", image_size = 256, batch_size = 4, epochs = 4, augmentation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train a model by specifying training source , image size , training parameters, \n",
    "\n",
    "perf = evaluate_performance(test_model.test_labels, test_model.predictions)\n",
    "print (perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mysource = \"sunnybrook\"\n",
    "img_size = 256\n",
    "mymodel = train_unet_model (source_path = UNET_TRAIN_DIR, model_path = UNET_MODEL_DIR, source = mysource, \\\n",
    "                         image_size= img_size, batch_size= 4, epochs= 2, augmentation= False, model_summary= False)\n",
    "\n",
    "mymodel.plot_accuracy_and_loss()\n",
    "mymodel.display_ytrue_ypred(num_images = 4, random_images = True, evaluate = True)\n",
    "#mymodel.display_ytrue_ypred(num_images = 6, random_images = True, evaluate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predictions on Sunnybrook or ACDC test images using pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Prediction using pre-trained weights\n",
    "###################\n",
    "\n",
    "image_file = UNET_TRAIN_DIR + \"sunnybrook_176_test_images.npy\"\n",
    "label_file = UNET_TRAIN_DIR + \"sunnybrook_176_test_labels.npy\" \n",
    "\n",
    "\n",
    "img_size = 176\n",
    "model_file = \"/masvol/heartsmart/unet_model/models_baseline/combined_176.hdf5\"\n",
    "mymodel = predict_with_pretrained_weights(model_file, image_size = img_size, \\\n",
    "                                test_image_file= image_file, test_label_file = label_file)\n",
    "\n",
    "#save the predictions in the form of numpy array\n",
    "# pred_file = \"/masvol/heartsmart/unet_model/data/dsb200_256_predictions.npy\"\n",
    "# np.save(pred_file, mymodel.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance measures such as precision, recall, f1 score on the model\n",
    "perf = evaluate_performance(mymodel.test_labels, mymodel.predictions)\n",
    "print (perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load np arrays of images and labels...\n",
      "------------------------------\n",
      "Loading files :  /masvol/heartsmart/unet_model/data/sunnybrook_176_test_images.npy /masvol/heartsmart/unet_model/data/sunnybrook_176_test_labels.npy\n",
      "shape, max, min, mean of original image set: (80, 176, 176, 1) 1749.0 0.0 113.759094\n",
      "shape, max, min, mean after normalization  : (80, 176, 176, 1) 1.0 0.0 0.17185494\n",
      "shape, max, min, mean of labels : (80, 176, 176, 1) 1.0 0.0 0.07099206\n"
     ]
    }
   ],
   "source": [
    "image_file = UNET_TRAIN_DIR + \"sunnybrook_176_test_images.npy\"\n",
    "label_file = UNET_TRAIN_DIR + \"sunnybrook_176_test_labels.npy\" \n",
    "test_data = {}\n",
    "test_data[\"images\"] = image_file\n",
    "test_data[\"labels\"] = label_file\n",
    "\n",
    "ts , tl= load_images_and_labels(test_data)\n",
    "\n",
    "# print('-'*30)\n",
    "# print (\"Creating U-net model...\")\n",
    "# myunet = myUnet(image_size = image_size, model_type = \"large\")\n",
    "# print('-'*30)\n",
    "# print (\"Loading the pre-trained weights...\")\n",
    "# myunet.load_pretrained_weights(model_file)\n",
    "# print('-'*30)\n",
    "\n",
    "# print('Run predictions...')\n",
    "# myunet.predict(test_image_array = ts, test_label_array = tl)\n",
    "# print('-'*30)\n",
    "\n",
    "# myunet.display_ytrue_ypred(num_images = 4, random_images = False, evaluate = False)\n",
    "# return myunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2302156  175924]\n",
      "2478080\n"
     ]
    }
   ],
   "source": [
    "# used balanced class weights .... n_samples / (n_classes * np.bincount(y))\n",
    "tl2 = tl.flatten().astype('int32')\n",
    "weights = (tl2.shape[0])/(2*np.bincount(tl2))\n",
    "class_weights = {}\n",
    "class_weights[0] = weights[0]\n",
    "class_weights[1] = weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "class_weights[0] = weights[0]\n",
    "class_weights[1] = weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5382085314809248, 1: 7.043041313294377}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predictions on DSB2 data using pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Prediction using pre-trained weights\n",
    "###################\n",
    "\n",
    "# image_file = UNET_TRAIN_DIR + \"sunnybrook_256_test_images.npy\"\n",
    "# label_file = UNET_TRAIN_DIR + \"sunnybrook_256_test_labels.npy\" \n",
    "\n",
    "#image_file = \"/masvol/heartsmart/unet_model/data/dsb300_256.npy\"\n",
    "\n",
    "test_image_list = [ \"/opt/output/dsb/norm/1/3/unet_model_test/data/dsb_884_256_train.npy\", \\\n",
    "                \"/opt/output/dsb/norm/1/3/unet_model_test/data/dsb_885_256_train.npy\", \\\n",
    "                 \"/opt/output/dsb/norm/1/3/unet_model_test/data/dsb_886_256_train.npy\", \\\n",
    "                 \"/opt/output/dsb/norm/1/3/unet_model_test/data/dsb_887_256_train.npy\", \\\n",
    "                ]\n",
    "\n",
    "image_size = 256\n",
    "model_file = \"/masvol/heartsmart/unet_model/models_baseline/combined_256.hdf5\"\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "print (\"Creating U-net model...\")\n",
    "mymodel256 = myUnet(image_size = image_size, model_type = \"large\")\n",
    "print('-'*30)\n",
    "print (\"Loading the pre-trained weights...\")\n",
    "mymodel256.load_pretrained_weights(model_file)\n",
    "print('-'*30)\n",
    "\n",
    "for image_file in test_image_list:\n",
    "    ts = load_images(image_file)\n",
    "    tl = \"none\"\n",
    "    print('Run predictions...')\n",
    "    mymodel256.predict(test_image_array = ts, test_label_array = tl)\n",
    "    print('-'*30)\n",
    "    mymodel256.display_ytrue_ypred(num_images = 4, random_images = False, evaluate = False)\n",
    "    #pick_min_max (mymodel256.predictions)\n",
    "    #mymodel256.predictions (2, 256, 256, 1)\n",
    "    \n",
    "    #save the predictions in the form of numpy array\n",
    "    # pred_file = \"/masvol/heartsmart/unet_model/data/dsb200_256_predictions.npy\"\n",
    "    # np.save(pred_file, mymodel256.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Prediction using pre-trained weights\n",
    "###################\n",
    "\n",
    "# image_file = UNET_TRAIN_DIR + \"sunnybrook_256_test_images.npy\"\n",
    "# label_file = UNET_TRAIN_DIR + \"sunnybrook_256_test_labels.npy\" \n",
    "\n",
    "#image_file = \"/masvol/heartsmart/unet_model/data/dsb300_256.npy\"\n",
    "image_file = \"/opt/output/dsb/norm/1/3/unet_model_test/data/dsb_889_176_train.npy\"\n",
    "label_file = \"none\" \n",
    "\n",
    "img_size = 176\n",
    "model_file = \"/masvol/heartsmart/unet_model/models_baseline/combined_176.hdf5\"\n",
    "mymodel256 = predict_with_pretrained_weights(model_file, image_size = img_size, \\\n",
    "                                test_image_file= image_file, test_label_file = label_file)\n",
    "\n",
    "#save the predictions in the form of numpy array\n",
    "# pred_file = \"/masvol/heartsmart/unet_model/data/dsb200_256_predictions.npy\"\n",
    "# np.save(pred_file, mymodel256.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mymodel256.display_ypred (num_images = 10, random_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Prediction using pre-trained weights\n",
    "###################\n",
    "\n",
    "# image_file = UNET_TRAIN_DIR + \"sunnybrook_256_test_images.npy\"\n",
    "# label_file = UNET_TRAIN_DIR + \"sunnybrook_256_test_labels.npy\" \n",
    "\n",
    "image_file = \"/masvol/heartsmart/unet_model/data/dsb200_176.npy\"\n",
    "label_file = \"none\" \n",
    "\n",
    "img_size = 176\n",
    "model_file = \"/masvol/heartsmart/unet_model/models_baseline/combined_176.hdf5\"\n",
    "mymodel176 = predict_with_pretrained_weights(model_file, image_size = img_size, \\\n",
    "                                test_image_file= image_file, test_label_file = label_file)\n",
    "\n",
    "#save the predictions in the form of numpy array\n",
    "pred_file = \"/masvol/heartsmart/unet_model/data/dsb200_176_predictions.npy\"\n",
    "np.save(pred_file, mymodel176.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_all_models( batch_size = 4, epochs = 2, augmentation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel.display_ytrue_ypred(num_images = 6, random_images = True, evaluate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mymodel176.display_ypred (num_images = 10, random_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
