{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip show tensorflow\n",
    "# ! pip show tensorflow-gpu\n",
    "# !pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import cv2 \n",
    "import re, sys\n",
    "import fnmatch, shutil, subprocess\n",
    "from IPython.utils import io\n",
    "import glob\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, concatenate, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "#Fix the random seeds for numpy (this is for Keras) and for tensorflow backend to reduce the run-to-run variance\n",
    "from numpy.random import seed\n",
    "seed(100)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\nSuccessfully imported packages!!!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "# #config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# #config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "# #sess.run(yourcommand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.1  # train/test split ratio for Sunnybrook and ACDC data\n",
    "\n",
    "BASE_DIR = \"/opt/output/\"\n",
    "SOURCE = \"sunnybrook\"\n",
    "TRAIN_IMG_DIR = BASE_DIR + SOURCE + \"/norm/1/3/images/\"\n",
    "TRAIN_LBL_DIR = BASE_DIR + SOURCE + \"/norm/1/3/labels/\"\n",
    "\n",
    "TEST_IMG_DIR = BASE_DIR + SOURCE + \"/norm/1/3/images/\"\n",
    "PRED_RESULT_DIR = BASE_DIR + SOURCE + \"/norm/1/3/images/\"\n",
    "\n",
    "UNET_TRAIN_DIR = BASE_DIR + SOURCE + \"/unet_model/data/\"\n",
    "UNET_MODEL_DIR = BASE_DIR + SOURCE + \"/unet_model/models/\"\n",
    "\n",
    "\n",
    "UNET_TRAIN_DIR = \"/masvol/heartsmart/unet_model/data/\"\n",
    "UNET_MODEL_DIR = \"/masvol/heartsmart/unet_model/models/\"\n",
    "\n",
    "# UNET_TRAIN_DIR = \"/opt/heartsmart/unet_model/data/\"\n",
    "# UNET_MODEL_DIR = \"/opt/heartsmart/unet_model/models/\"\n",
    "\n",
    "DSB_SOURCE = \"dsb\"\n",
    "DSB_TRAIN_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/train/\"\n",
    "DSB_VAL_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/validate/\"\n",
    "DSB_TEST_IMG_DIR = BASE_DIR + DSB_SOURCE + \"/norm/1/3/test/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to extract sunnybrook contour files and corresponding image files \n",
    "#### And save them as 4d numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Methods to extract sunnybrook contour files and corresponding image files \n",
    "#\n",
    "###################################\n",
    "\n",
    "SAX_SERIES_ALL = {\n",
    "    'SC-HF-I-1': '0004',\n",
    "    'SC-HF-I-2': '0106',\n",
    "    'SC-HF-I-4': '0116',\n",
    "    'SC-HF-I-5': '0156',\n",
    "    'SC-HF-I-6': '0180',\n",
    "    'SC-HF-I-7': '0209',\n",
    "    'SC-HF-I-8': '0226',\n",
    "    'SC-HF-I-9': '0241',\n",
    "    'SC-HF-I-10': '0024',\n",
    "    'SC-HF-I-11': '0043',\n",
    "    'SC-HF-I-12': '0062',\n",
    "    'SC-HF-I-40': '0134',\n",
    "    'SC-HF-NI-3': '0379',\n",
    "    'SC-HF-NI-4': '0501',\n",
    "    'SC-HF-NI-7': '0523',\n",
    "    'SC-HF-NI-12': '0286',\n",
    "    'SC-HF-NI-11': '0270',\n",
    "    'SC-HF-NI-13': '0304',\n",
    "    'SC-HF-NI-14': '0331',\n",
    "    'SC-HF-NI-15': '0359',\n",
    "    'SC-HF-NI-31': '0401',\n",
    "    'SC-HF-NI-33':'0424',\n",
    "    'SC-HF-NI-34': '0446',\n",
    "    'SC-HF-NI-36': '0474',\n",
    "    'SC-HYP-1': '0550',\n",
    "    'SC-HYP-3': '0650',\n",
    "    'SC-HYP-6': '0767',\n",
    "    'SC-HYP-7': '0007',\n",
    "    'SC-HYP-8': '0796',\n",
    "    'SC-HYP-9': '0003',\n",
    "    'SC-HYP-10': '0579',\n",
    "    'SC-HYP-11': '0601',\n",
    "    'SC-HYP-12': '0629',\n",
    "    'SC-HYP-37': '0702',\n",
    "    'SC-HYP-38': '0734',\n",
    "    'SC-HYP-40': '0755',\n",
    "    'SC-N-2': '0898',\n",
    "    'SC-N-3': '0915',\n",
    "    'SC-N-5': '0963',\n",
    "    'SC-N-6': '0981',\n",
    "    'SC-N-7': '1009',\n",
    "    'SC-N-9': '1031',\n",
    "    'SC-N-10': '0851',\n",
    "    'SC-N-11': '0878',\n",
    "    'SC-N-40': '0944',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def shrink_case(case):\n",
    "    toks = case.split(\"-\")\n",
    "    def shrink_if_number(x):\n",
    "        try:\n",
    "            cvt = int(x)\n",
    "            return str(cvt)\n",
    "        except ValueError:\n",
    "            return x\n",
    "    return \"-\".join([shrink_if_number(t) for t in toks])\n",
    "\n",
    "class Contour(object):\n",
    "    def __init__(self, ctr_path):\n",
    "        self.ctr_path = ctr_path                \n",
    "        match = re.search(r\"/([^/]*)/IM-(\\d{4})-(\\d{4}).dcm.label.npy\", ctr_path)\n",
    "        self.case = shrink_case(match.group(1))\n",
    "        self.record = int(match.group(2))\n",
    "        self.img_no = int(match.group(3))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"<Contour for case %s, record %d image %d>\" % (self.case, self.record, self.img_no)\n",
    "    \n",
    "    __repr__ = __str__\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    x,y = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[startx:startx+cropx, starty:starty+cropy]\n",
    "\n",
    "def pad_image(img, img_size):\n",
    "    #print (\"input shape : \", img.shape)\n",
    "    pad_x=0\n",
    "    pad_y=0\n",
    "    x,y = img.shape\n",
    "    if (x<img_size):\n",
    "        pad_x = img_size - x\n",
    "    if (y<img_size):\n",
    "        pad_y = img_size - y\n",
    "    process_img = np.pad(img, pad_width=((pad_x//2, ((pad_x//2) + (pad_x % 2))), (pad_y//2, ((pad_y//2) + (pad_y % 2)))), mode = 'constant', constant_values = 0)\n",
    "    #print (\"output shape : \", process_img.shape)\n",
    "    return process_img\n",
    "\n",
    "\n",
    "def load_contour(contour, img_path, crop_size):\n",
    "    # file = IM-0851-0127.dcm.npy\n",
    "    filename = \"IM-%s-%04d.dcm.npy\" % (SAX_SERIES_ALL[contour.case], contour.img_no)\n",
    "    full_path = os.path.join(img_path, contour.case, filename)\n",
    "    img = np.load(full_path)\n",
    "    label = np.load(contour.ctr_path)\n",
    "    height, width = img.shape\n",
    "    height_l, width_l = label.shape\n",
    "    if height != crop_size or width !=crop_size:\n",
    "        #print (\"img: \", contour.img_no, height, width)\n",
    "        #print (\"lbl: \", height_l, width_l)\n",
    "        img = crop_center(img,crop_size,crop_size)\n",
    "        label = crop_center(label,crop_size,crop_size)\n",
    "    return img, label\n",
    "\n",
    "   \n",
    "def get_all_contours(contour_path):\n",
    "    contours = [os.path.join(dirpath, f)\n",
    "        for dirpath, dirnames, files in os.walk(contour_path)\n",
    "        for f in fnmatch.filter(files, 'IM-*dcm.label.npy')]\n",
    "    print(\"Number of examples: {:d}\".format(len(contours)))\n",
    "    print(\"Shuffle data\")\n",
    "    np.random.shuffle(contours)\n",
    "    print (contours[0], contours[-1])\n",
    "    print(\"Number of examples after cleanup: {:d}\".format(len(contours)))\n",
    "    extracted = list(map(Contour, contours))\n",
    "    print (\"Contour 0 :\", extracted[0].case, extracted[0].record, extracted[0].img_no)\n",
    "    print (\"Contour -1 :\", extracted[-1].case, extracted[-1].record, extracted[-1].img_no) \n",
    "    return extracted\n",
    "\n",
    "def get_contours_and_images(contours, img_path, crop_size):\n",
    "\n",
    "    num_contours = len(contours)\n",
    "    print(\"Processing {:d} images and labels...\".format(num_contours))        \n",
    "    imgs, labels = [], []\n",
    "        \n",
    "    for idx,ctr in enumerate(contours):\n",
    "        img, label = load_contour(ctr, img_path, crop_size)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if idx % (num_contours//5) == 0: # print up to 5 images\n",
    "            print (img.shape, img_path)\n",
    "            f, axs = plt.subplots(1,3,figsize=(12,12))\n",
    "            plt.subplot(131),plt.imshow(img, cmap = 'gray')\n",
    "            plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(132),plt.imshow(label, cmap = 'gray')\n",
    "            plt.title('label'), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(133),plt.imshow(img, cmap = 'gray')\n",
    "            plt.imshow(label, 'jet', interpolation='none', alpha=0.5)\n",
    "            plt.title('label'), plt.xticks([]), plt.yticks([])\n",
    "            plt.show()\n",
    "\n",
    "    print(\"Processed {:d} images and labels...\".format(len(imgs))) \n",
    "    return imgs, labels\n",
    "\n",
    "def save_training_data(imgs, lbls, save_file_path, file_prefix, image_size):\n",
    "    rows = image_size\n",
    "    cols = image_size\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print(\"Creating training data..input size : \",len(imgs))\n",
    "    print('-'*30)\n",
    "    print(\"Converting data to np array\")\n",
    "    \n",
    "    imgdatas = np.ndarray((len(imgs),rows,cols,1), dtype=np.int)\n",
    "    \n",
    "    imglabels = np.ndarray((len(imgs),rows,cols,1), dtype=np.uint8)\n",
    "    \n",
    "    for idx in range(len(imgs)):\n",
    "        img = imgs[idx]\n",
    "        label = lbls[idx]\n",
    "        img = img_to_array(img)\n",
    "        label = img_to_array(label)\n",
    "        \n",
    "        try:\n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        \n",
    "    imgfile = save_file_path + file_prefix +\"_images.npy\"\n",
    "    print (imgfile)\n",
    "    lblfile = save_file_path + file_prefix +\"_labels.npy\"\n",
    "    np.save(imgfile, imgdatas)\n",
    "    np.save(lblfile, imglabels)\n",
    "\n",
    "    print (\"Shape of data & label np arrays : \", imgdatas.shape, imglabels.shape)\n",
    "    print (imgdatas.max(), imgdatas.min(), imglabels.max(), imglabels.min())\n",
    "    print('Saved data as: ', imgfile, lblfile )\n",
    "\n",
    "\n",
    "def extract_sunnybrook_training_data(crop_size=256): \n",
    "    SPLIT_RATIO = TRAIN_TEST_SPLIT_RATIO  # train/test split ratio\n",
    "    print(\"Mapping ground truth contours to images...\")\n",
    "    ctrs = get_all_contours(TRAIN_LBL_DIR)\n",
    "    print(\"Done mapping ground truth contours to images\")\n",
    "    test_ctrs = ctrs[0:int(SPLIT_RATIO*len(ctrs))]\n",
    "    train_ctrs = ctrs[int(SPLIT_RATIO*len(ctrs)):]\n",
    "    print(\"Split train_set:%d, test_set:%d\"%(len(train_ctrs), len(test_ctrs)))\n",
    "    print (\"Extracting Training Images and Labels\")\n",
    "    train_imgs, train_labels = get_contours_and_images(train_ctrs, TRAIN_IMG_DIR, crop_size)\n",
    "    print (\"Extracting Test Images and Labels\")\n",
    "    test_imgs, test_labels = get_contours_and_images(test_ctrs, TRAIN_IMG_DIR, crop_size)\n",
    "    print(\"Extracted Images train_set:%d, test_set:%d\"%(len(train_imgs), len(test_imgs)))\n",
    "    return train_imgs, train_labels, test_imgs, test_labels \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ##Get sunnybrook images and labels with crop from center to get 256x256 images\n",
    "    train_imgs, train_labels, test_imgs, test_labels = extract_sunnybrook_training_data(crop_size=256)\n",
    "\n",
    "    ##Get sunnybrook images and labels with crop from center to get 180x180 images\n",
    "\n",
    "    train_imgs2, train_labels2, test_imgs2, test_labels2 = extract_sunnybrook_training_data(crop_size=176)\n",
    "\n",
    "    ### Create 256x256 size train/test data in 4d tensor shape and save them\n",
    "    save_location = UNET_TRAIN_DIR\n",
    "    tr_file_prefix = SOURCE + \"_256_train\"\n",
    "    tst_file_prefix = SOURCE + \"_256_test\"\n",
    "    save_training_data(train_imgs, train_labels, save_location, tr_file_prefix, image_size = 256)\n",
    "    save_training_data(test_imgs, test_labels, save_location, tst_file_prefix, image_size = 256)\n",
    "\n",
    "    ### Create 180x180 size train/test data in 4d tensor shape and save them\n",
    "    tr_file_prefix = SOURCE + \"_176_train\"\n",
    "    tst_file_prefix = SOURCE + \"_176_test\"\n",
    "\n",
    "    save_training_data(train_imgs2, train_labels2, save_location, tr_file_prefix, image_size = 176)\n",
    "    save_training_data(test_imgs2, test_labels2, save_location, tst_file_prefix, image_size = 176)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to process and save DSB2 data set into 4d numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#\n",
    "# Methods to process and save DSB2 data set into 4d numpy arrays\n",
    "#\n",
    "################################################\n",
    "\n",
    "\n",
    "def shrink_case(case):\n",
    "    toks = case.split(\"-\")    \n",
    "    def shrink_if_number(x):\n",
    "        try:\n",
    "            cvt = int(x)\n",
    "            return str(cvt)\n",
    "        except ValueError:\n",
    "            return x\n",
    "    return \"-\".join([shrink_if_number(t) for t in toks])\n",
    "\n",
    "class Image_info_map(object):\n",
    "    def __init__(self, ctr_path):\n",
    "        self.ctr_path = ctr_path\n",
    "        #print (ctr_path)\n",
    "        #/opt/output/dsb/norm/1/3/test/1111/sax_13_IM-2680-0008.dcm.npy\n",
    "        match = re.search(r\"/([^/]*)/sax_(\\d+)_IM-(\\d+)-(\\d+).dcm.npy\", ctr_path)\n",
    "        #match = re.search(r\"/([^/]*)/patient\\d+_slice(\\d+)_frame(\\d+)_label_fix.nii.npy\", ctr_path)\n",
    "        try:\n",
    "            self.case = shrink_case(match.group(1))\n",
    "            self.sax_num = int (match.group(2))\n",
    "            self.record = int(match.group(3))\n",
    "            self.img_no = int(match.group(4))\n",
    "        except AttributeError:\n",
    "            #/opt/output/dsb/norm/1/3/train/234/sax_20_IM-3098-0022-0007.dcm.npy\n",
    "            match = re.search(r\"/([^/]*)/sax_(\\d+)_IM-(\\d+)-(\\d+)-(\\d+).dcm.npy\", ctr_path)\n",
    "            self.case = shrink_case(match.group(1))\n",
    "            self.sax_num = int (match.group(2))\n",
    "            self.record = int(match.group(3))\n",
    "            self.img_no = int(match.group(5))\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"<Image info for case %s, record %d image %d>\" % (self.case, self.record, self.img_no)\n",
    "    \n",
    "def get_dsb_image_list2(data_path):\n",
    "    image_list = [os.path.join(dirpath,f) \n",
    "            for files in glob.glob(data_path+\"/*\") \n",
    "            for dirpath, dirname, infiles in os.walk(files) \n",
    "            for f in infiles if f.endswith('dcm.npy')]\n",
    "    \n",
    "    print(\"Number of examples: {:d}\".format(len(image_list)))\n",
    "    #print(\"Shuffle data\")\n",
    "    #np.random.shuffle(image_list)\n",
    "    print (image_list[0], image_list[-1])\n",
    "    \n",
    "    extracted = list(map(Image_info_map, image_list))\n",
    "    print (\"Image 0 :\", extracted[0].case, extracted[0].record, extracted[0].img_no)\n",
    "    print (\"Imae -1 :\", extracted[-1].case, extracted[-1].record, extracted[-1].img_no) \n",
    "    return image_list, extracted\n",
    "\n",
    "def get_dsb_image_list(data_path):\n",
    "    image_list = [os.path.join(data_path,files) \n",
    "            for files in glob.glob(data_path+\"/*\") if files.endswith('dcm.npy')]\n",
    "    \n",
    "    print(\"Number of examples: {:d}\".format(len(image_list)))\n",
    "    #print(\"Shuffle data\")\n",
    "    #np.random.shuffle(image_list)\n",
    "    print (image_list[0], image_list[-1])\n",
    "    \n",
    "    extracted = list(map(Image_info_map, image_list))\n",
    "    print (\"Image 0 :\", extracted[0].case, extracted[0].record, extracted[0].img_no)\n",
    "    print (\"Imae -1 :\", extracted[-1].case, extracted[-1].record, extracted[-1].img_no) \n",
    "    return image_list, extracted\n",
    "\n",
    "def get_dsb_images(data_path, crop_size):\n",
    "    print (\"data path: \", data_path)\n",
    "    img_path_list, extracted_info = get_dsb_image_list(data_path)\n",
    "    img_count = len(img_path_list)\n",
    "    print(\"Processing {:d} images and labels...\".format(img_count))\n",
    "    \n",
    "    imgs , img_path, ext_info = [], [], []\n",
    "    for i in range(img_count):\n",
    "\n",
    "        full_path = img_path_list[i]\n",
    "        img = np.load(full_path)\n",
    "        x,y = img.shape\n",
    "\n",
    "        if x < crop_size or y < crop_size:\n",
    "            #print (\"shapes smaller than crop size\", x, y, crop_size)\n",
    "            img = pad_image(img, crop_size)\n",
    "            #continue\n",
    "        if x > crop_size or y > crop_size:\n",
    "            #print (\"img: \", i, x, y, full_path)\n",
    "            img = crop_center(img,crop_size,crop_size)\n",
    "            \n",
    "        imgs.append(img)\n",
    "        img_path.append(full_path)\n",
    "        ext_info.append(extracted_info[i])\n",
    "\n",
    "        if i % (img_count//5) == 0:\n",
    "            print (full_path)\n",
    "            plt.imshow(img, cmap = 'gray')\n",
    "            plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "            plt.show()\n",
    "\n",
    "            #except IOError:\n",
    "            #    continue\n",
    "    print (\"Final size of image set :\", len(imgs), \"dropped images:\", (img_count - len(imgs)))\n",
    "                \n",
    "    return imgs, img_path, ext_info\n",
    "\n",
    "def convert_images_to_nparray_and_save (imgs, save_file, image_size):\n",
    "    rows = image_size\n",
    "    cols = image_size\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print(\"Converting data to np array, Input size : \",len(imgs))\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgdatas = np.ndarray((len(imgs),rows,cols,1), dtype=np.int)\n",
    "        \n",
    "    for idx in range(len(imgs)):\n",
    "        img = imgs[idx]\n",
    "        img = img_to_array(img)        \n",
    "        try:\n",
    "            imgdatas[i] = img\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        \n",
    "    np.save(save_file, imgdatas)\n",
    "\n",
    "    print (\"Shape of image array : \", imgdatas.shape)\n",
    "    print (\"Max, min, mean values\", imgdatas.max(), imgdatas.min(), imgdatas.mean())\n",
    "    print('Saved data as: ', save_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patient_record = \"118\"\n",
    "data_path = DSB_TRAIN_IMG_DIR + patient_record\n",
    "#image_list, image_path_list, extracted_info = get_dsb_images(data_path, crop_size=176)\n",
    "image_list2, image_path_list2, extracted_info2 = get_dsb_images(data_path, crop_size=256)\n",
    "\n",
    "#img_file = UNET_TRAIN_DIR + DSB_SOURCE + patient_record + \"_176.npy\"\n",
    "#convert_images_to_nparray_and_save (image_list, img_file, image_size = 176)\n",
    "\n",
    "img_file2 = UNET_TRAIN_DIR + DSB_SOURCE + patient_record + \"_256.npy\"\n",
    "convert_images_to_nparray_and_save (image_list2, img_file2, image_size = 256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here  if training/test data are already stored in unet_model/data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to load 4d np array for images from ./data directory, perform pixel normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#\n",
    "# Methods to load 4d np array for images from ./data directory\n",
    "# 4D tensor with shape: (samples, rows, cols, channels=1)\n",
    "#\n",
    "#########################################\n",
    "\n",
    "def load_images_and_labels(data):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images and labels...')\n",
    "    print('-'*30)\n",
    "    imgfile = data[\"images\"]\n",
    "    labelfile = data[\"labels\"]\n",
    "    print (\"Loading files : \", imgfile, labelfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    lb = np.load(labelfile)\n",
    "    images = im.astype('float32')\n",
    "    labels = lb.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    print(\"shape, max, min, mean of labels :\", labels.shape, labels.max(), labels.min(), labels.mean())\n",
    "    return images2, labels\n",
    "\n",
    "\n",
    "def load_images(imgfile):\n",
    "    print('-'*30)\n",
    "    print('load np arrays of images ...')\n",
    "    print('-'*30)\n",
    "    print (\"Loading files : \", imgfile)\n",
    "    \n",
    "    im = np.load(imgfile)\n",
    "    images = im.astype('float32')\n",
    "    \n",
    "    ##Normalize the pixel values, (between 0..1)\n",
    "    x_min = images.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = images.max(axis=(1, 2), keepdims=True)\n",
    "    images2 = (images - x_min)/(x_max-x_min)\n",
    "\n",
    "    print(\"shape, max, min, mean of original image set:\", images.shape, images.max(), images.min(), images.mean())\n",
    "    print(\"shape, max, min, mean after normalization  :\", images2.shape, images2.max(), images2.min(), images2.mean())\n",
    "    return images2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# img_file = \"/masvol/heartsmart/unet_model/data/dsb118_256.npy\"\n",
    "\n",
    "# patient_rec = load_images(img_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#\n",
    "# Loss functions\n",
    "#\n",
    "#########################################\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_dice_coeff(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = 1 - weighted_dice_coeff(y_true, y_pred, weight)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                          (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "\n",
    "\n",
    "def my_bce_loss(y_true, y_pred):\n",
    "#     y_true = K.cast(y_true, 'float32')\n",
    "#     y_pred = K.cast(y_pred, 'float32')\n",
    " \n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = (y_true * K.log(y_pred[i])) + ((1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean(loss, axis=-1)        \n",
    "    #return K.sum(loss)\n",
    "# def my_bce_loss(y_true, y_pred):\n",
    "#     y_true_f = y_true.flatten()\n",
    "#     y_pred_f = y_pred.flatten()\n",
    "    \n",
    "#     # avoiding overflow\n",
    "#     epsilon = 1e-7\n",
    "#     y_pred_f[y_pred_f<=0.] = epsilon\n",
    "#     y_pred_f[y_pred_f>=1.] = 1. -epsilon\n",
    "#     #y_pred = K.clip(y_pred_f, epsilon, 1. - epsilon)\n",
    "#     #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "#     result = []\n",
    "#     result.append([y_true[i] * math.log(y_pred[i]) + (1 - y_true[i]) * math.log(1 - y_pred[i]) \\\n",
    "#                    for i in range(len(y_pred))])\n",
    "#     return np.mean(result)\n",
    "\n",
    "\n",
    "\n",
    "def penalized_bce_loss(weight):\n",
    "    def weighted_bce_loss(y_true, y_pred):\n",
    "        # avoiding overflow\n",
    "        epsilon = 1e-7\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "        loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "        return K.sum(loss) / K.sum(weight)\n",
    "    return weighted_bce_loss\n",
    "\n",
    "def penalized_bce_loss2(weight):\n",
    "    def weighted_bce_loss(y_true, y_pred):\n",
    "        # avoiding overflow\n",
    "        epsilon = 1e-7\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "        loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                              (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "        return K.sum(loss) / K.sum(weight)\n",
    "    return weighted_bce_loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + (1 - weighted_dice_coeff(y_true, y_pred, weight))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# \n",
    "# Method to evaluate the performance of u-net by computing, logloss, precision, reccall, f1score etc\n",
    "#\n",
    "#################################################\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    y_pred_r = np.round(y_pred_f)\n",
    "\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred_f[y_pred_f<=0.] = epsilon\n",
    "    y_pred_f[y_pred_f>=1.] = 1. -epsilon\n",
    "    #y_pred = K.clip(y_pred_f, epsilon, 1. - epsilon)\n",
    "    #logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    perf = {}\n",
    "    result = []\n",
    "    result2 = []\n",
    "    \n",
    "    true_p = 0.0\n",
    "    true_n = 0.0\n",
    "    false_p = 0.0\n",
    "    false_n = 0.0\n",
    "    for i in range (len(y_pred_f)):\n",
    "        result.append (y_true_f[i] * np.log(y_pred_f[i]) + (1 - y_true_f[i]) * np.log(1 - y_pred_f[i]))\n",
    "        result2.append (y_true_f[i] * np.log2(y_pred_f[i]) + (1 - y_true_f[i]) * np.log2(1 - y_pred_f[i]))\n",
    "\n",
    "        if (y_pred_r[i] == 0 and y_true_f[i] == 0):\n",
    "            true_n += 1.\n",
    "        elif (y_pred_r[i] == 0 and y_true_f[i] == 1):\n",
    "            false_n += 1.\n",
    "        elif (y_pred_r[i] == 1 and y_true_f[i] == 1):\n",
    "            true_p += 1.\n",
    "        elif (y_pred_r[i] == 1 and y_true_f[i] == 0):\n",
    "            false_p += 1.\n",
    "            \n",
    "    loss = np.mean(result)\n",
    "    loss2 = np.mean(result2)\n",
    "    accuracy = (true_p + true_n)/(true_p + true_n + false_p + false_n)\n",
    "    precision = true_p/(true_p + false_p)\n",
    "    recall    = true_p/(true_p + false_n)\n",
    "    f1_score = (2 * precision * recall)/(precision+recall)\n",
    "    \n",
    "    print (len(result), sum(result))\n",
    "    print (\"true_pos : %d, false_pos : %d, true_neg  %d, false_neg : %d\"%(true_p, false_p, true_n, false_n))\n",
    "    print (\"accuracy : %f, precision : %f, recall  %f, f1_score : %f\"%(accuracy, precision, recall, f1_score))\n",
    "    print (\"logloss : %f, log2loss : %f \"%(loss, loss2))\n",
    "    perf[\"logloss\"] = loss\n",
    "    perf[\"log2loss\"] = loss2\n",
    "    perf[\"true_positive\"] = true_p\n",
    "    perf[\"false_positive\"] = false_p\n",
    "    perf[\"true_negative\"] = true_n\n",
    "    perf[\"false_negative\"] = false_n\n",
    "    perf[\"accuracy\"] = accuracy\n",
    "    perf[\"precision\"] = precision\n",
    "    perf[\"recall\"] = recall\n",
    "    perf[\"f1_score\"] = f1_score\n",
    "    \n",
    "    return perf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#\n",
    "# Unet models\n",
    "#\n",
    "################################\n",
    "\n",
    "class myUnet(object):\n",
    "\n",
    "    def __init__(self, image_size = 256, model_type = \"small\"):\n",
    "        self.img_rows = image_size\n",
    "        self.img_cols = image_size\n",
    "        self.model_type = model_type\n",
    "        if model_type == \"small\":\n",
    "            self.build_unet_small()\n",
    "        elif model_type == \"large\":\n",
    "            self.build_unet()\n",
    "        elif model_type == \"large2\":\n",
    "            self.build_unet()\n",
    "        else :\n",
    "            print (\"Specify valid model_type (small, large, large2)\")\n",
    "            return\n",
    "\n",
    "    def load_data(self, train_data, test_data):\n",
    "        print('-'*30)\n",
    "        print(\"loading data\")\n",
    "        self.train_images, self.train_labels = load_images_and_labels(train_data)\n",
    "        self.test_images, self.test_labels = load_images_and_labels(test_data)       \n",
    "        print(\"loading data done\")\n",
    "        print('-'*30)\n",
    "\n",
    "    def build_unet_small(self):\n",
    "        \n",
    "        '''\n",
    "        Input shape\n",
    "        4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' \n",
    "        or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last' (default format).\n",
    "        \n",
    "        Output shape\n",
    "        4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or \n",
    "        4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format='channels_last'. \n",
    "        rows and cols values might have changed due to padding.\n",
    "        \n",
    "        He_normal initialization: It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) \n",
    "        where  fan_in is the number of input units in the weight tensor.\n",
    "        '''\n",
    "\n",
    "        print('-'*30)\n",
    "        print (\"Building smaller version of U-net model\")\n",
    "        print('-'*30)\n",
    "        \n",
    "        inputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "        conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "        conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "        conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        print (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "        conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        drop4 = Dropout(0.2)(conv4)\n",
    "        \n",
    "        up5 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop4))\n",
    "        merge5 = concatenate([conv3,up5], axis = 3)\n",
    "        conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
    "        conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        \n",
    "        up6 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "        merge6 = concatenate([conv2,up6], axis = 3)\n",
    "        conv6 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = concatenate([conv1,up7], axis = 3)\n",
    "        conv7 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        conv8 = Conv2D(1, 1, activation = 'sigmoid')(conv7)\n",
    "\n",
    "        self.model = Model(input = inputs, output = conv8)\n",
    "\n",
    "        self.model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])\n",
    "        #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    def build_unet(self):\n",
    "        \n",
    "        '''\n",
    "        Input shape\n",
    "        4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' \n",
    "        or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last' (default format).\n",
    "        \n",
    "        Output shape\n",
    "        4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or \n",
    "        4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format='channels_last'. \n",
    "        rows and cols values might have changed due to padding.\n",
    "        '''\n",
    "        print('-'*30)\n",
    "        print (\"Building U-net model\")\n",
    "        print('-'*30)\n",
    "        \n",
    "        inputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        print (\"conv1 shape:\",conv1.shape)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        print (\"conv2 shape:\",conv2.shape)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        print (\"conv3 shape:\",conv3.shape)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        print (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        #drop4 = Dropout(0.5)(conv4)\n",
    "        drop4 = conv4\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        merge6 = concatenate([drop4,up6], axis = 3)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = concatenate([conv3,up7], axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = concatenate([conv2,up8], axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = concatenate([conv1,up9], axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "        self.model = Model(input = inputs, output = conv10)\n",
    "\n",
    "        #self.model.compile(optimizer=RMSprop(lr=0.0001), loss=penalized_bce_loss(weight=0.08), metrics=['binary_accuracy'])\n",
    "        #self.model.compile(optimizer=RMSprop(lr=0.0001), loss=dice_loss, metrics=[dice_coeff])\n",
    "\n",
    "        #metrics=['accuracy'] calculates accuracy automatically from cost function. So using binary_crossentropy shows binary \n",
    "        #accuracy, not categorical accuracy.Using categorical_crossentropy automatically switches to categorical accuracy\n",
    "        #One can get both categorical and binary accuracy by using metrics=['binary_accuracy', 'categorical_accuracy']\n",
    "        \n",
    "        self.model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = [dice_coeff])\n",
    "        #self.model.compile(optimizer = Adam(lr = 1e-4), loss = my_bce_loss, metrics = ['binary_accuracy'])\n",
    "   \n",
    "\n",
    "\n",
    "    def train_and_predict(self, model_file, batch_size = 4, nb_epoch = 10): \n",
    "        self.model_file = model_file #path to save the weights with best model\n",
    "        model_checkpoint = ModelCheckpoint(self.model_file, monitor='loss',verbose=1, save_best_only=True)\n",
    "        print('-'*30)\n",
    "        print('Fitting model...')\n",
    "        print('-'*30)\n",
    "        self.history = self.model.fit(self.train_images, self.train_labels, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "        print('-'*30)\n",
    "        print('predict test data')\n",
    "        self.predictions = self.model.predict(self.test_images, batch_size=1, verbose=1)\n",
    "        scores = self.model.evaluate (self.predictions, self.test_labels, batch_size=4)\n",
    "        print (\"Prediction Scores\", scores)\n",
    "        pred_file = \"predictions_sk2.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        np.save(pred_file, self.predictions)\n",
    "        print('-'*30)\n",
    "        \n",
    "    \n",
    "    def train_with_augmentation(self, model_file, batch_size = 4, nb_epoch = 10 ):\n",
    "\n",
    "        sample_size, x_val, y_val, ax = self.train_images.shape\n",
    "\n",
    "        self.model_file = model_file #path to save the weights with best model\n",
    "        model_checkpoint = ModelCheckpoint(self.model_file, monitor='loss',verbose=1, save_best_only=True)\n",
    "        \n",
    "        # we create two instances with the same arguments\n",
    "        data_gen_args = dict(\n",
    "                             rotation_range=90.,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2)\n",
    "        \n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        seed = 1\n",
    "        image_generator = image_datagen.flow(self.train_images, y=None, seed = seed, batch_size=sample_size)\n",
    "        mask_generator = mask_datagen.flow(self.train_labels,  y=None, seed = seed, batch_size=sample_size)\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "        \n",
    "        print('-'*30)\n",
    "        print('Fitting model...')\n",
    "        \n",
    "        self.history = self.model.fit(self.train_images, self.train_labels, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "        \n",
    "        MAX_AUG=2\n",
    "        augmentation_round = 0\n",
    "        for img_tr, mask_tr in train_generator:\n",
    "                print (\"Augmentation round: \", augmentation_round+1, img_tr.shape)\n",
    "                s, x1, y1, p = img_tr.shape\n",
    "                self.history = self.model.fit(img_tr, mask_tr, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "                augmentation_round += 1\n",
    "                if (augmentation_round == MAX_AUG):\n",
    "                      break\n",
    "            \n",
    "        \n",
    "        print('-'*30)\n",
    "        print('Run Predictions on test data')\n",
    "        self.predictions = self.model.predict(self.test_images, batch_size=1, verbose=1)\n",
    "        scores = self.model.evaluate (self.predictions, self.test_labels, batch_size=4)\n",
    "        print (\"Prediction Scores\", scores)\n",
    "        pred_file = \"predictions_aug_sk1.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        np.save(pred_file, self.predictions)\n",
    "        print('-'*30)\n",
    "        \n",
    "\n",
    "    def train_with_augmentation2(self, model_file, batch_size = 4, nb_epoch = 10 ):\n",
    "\n",
    "        sample_size, x_val, y_val, ax = self.train_images.shape\n",
    "\n",
    "        model_file = UNET_MODEL_DIR+'unet_aug2.hdf5' #path to save the weights with best model\n",
    "        model_checkpoint = ModelCheckpoint(model_file, monitor='loss',verbose=1, save_best_only=True)\n",
    "        \n",
    "        # we create two instances with the same arguments\n",
    "        data_gen_args = dict(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=90.,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2)\n",
    "        \n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        seed = 1\n",
    "        image_datagen.fit(self.train_images, augment=True, seed=seed)\n",
    "        mask_datagen.fit(self.train_labels, augment=True, seed=seed)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        seed = 1\n",
    "        image_generator = image_datagen.flow(self.train_images, y=None, seed = seed, batch_size=sample_size)\n",
    "        mask_generator = mask_datagen.flow(self.train_labels,  y=None, seed = seed, batch_size=sample_size)\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "        \n",
    "        print('-'*30)\n",
    "        print('Fitting model...')\n",
    "        \n",
    "        self.model.fit(self.train_images, self.train_labels, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "        \n",
    "        MAX_AUG=2\n",
    "        augmentation_round = 0\n",
    "        for img_tr, mask_tr in train_generator:\n",
    "                print (\"Augmentation round: \", augmentation_round+1, img_tr.shape)\n",
    "                s, x1, y1, p = img_tr.shape\n",
    "                self.model.fit(img_tr, mask_tr, batch_size, nb_epoch, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "                augmentation_round += 1\n",
    "                if (augmentation_round == MAX_AUG):\n",
    "                      break\n",
    "            \n",
    "        \n",
    "        print('-'*30)\n",
    "        print('Run Predictions on test data')\n",
    "        self.predictions = self.model.predict(self.test_images, batch_size=1, verbose=1)\n",
    "        \n",
    "        pred_file = \"predictions_aug_sk1.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        np.save(pred_file, self.predictions)\n",
    "        print('-'*30)\n",
    "        \n",
    "\n",
    "    def save_img(self):\n",
    "        pred_file = \"predictions.npy\"\n",
    "        pred_file = UNET_TRAIN_DIR + pred_file\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load(pred_file)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"./%d.jpg\"%(i))\n",
    "    \n",
    "    def plot_accuracy_and_loss(self):\n",
    "        # list all data in history\n",
    "        print(self.history.history.keys())\n",
    "        history = self.history\n",
    "        # summarize history for accuracy\n",
    "        if 'dice_coeff' in self.history.history.keys():\n",
    "            plt.plot(history.history['dice_coeff'])\n",
    "            plt.plot(history.history['val_dice_coeff'])\n",
    "            plt.title('model accuracy(dice_coeff)')\n",
    "        elif 'val_acc' in self.history.history.keys():\n",
    "            plt.plot(history.history['acc'])\n",
    "            plt.plot(history.history['val_acc'])\n",
    "            plt.title('model accuracy')\n",
    "        elif 'categorical_accuracy' in self.history.history.keys():\n",
    "            plt.plot(history.history['categorical_accuracy'])\n",
    "            plt.plot(history.history['val_categorical_accuracy'])\n",
    "            plt.title('categorical_accuracy')\n",
    "        elif 'binary_accuracy' in self.history.history.keys():\n",
    "            plt.plot(history.history['binary_accuracy'])\n",
    "            plt.plot(history.history['val_binary_accuracy'])\n",
    "            plt.title('binary_accuracy')\n",
    "        else : \n",
    "            print (\"new loss function, not in the list\")\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Model for 176x176 images\n",
    "# Create a U-Net model, train the model and run the predictions and save the trained weights and predictions\n",
    "#\n",
    "##########################\n",
    "# /masvol/heartsmart/unet_model/data/sunnybrook_176_train_images.npy \n",
    "# /masvol/heartsmart/unet_model/data/sunnybrook_176_train_images.npy \n",
    "# /masvol/heartsmart/unet_model/data/sunnybrook_176_train_labels.npy\n",
    "train_data = {}\n",
    "train_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_176_train_images.npy\"\n",
    "train_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_176_train_labels.npy\"\n",
    "test_data = {}\n",
    "test_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_176_test_images.npy\"\n",
    "test_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_176_test_labels.npy\"\n",
    "\n",
    "model_file = UNET_MODEL_DIR+ SOURCE +'_176.hdf5'\n",
    "\n",
    "myunet = myUnet(image_size = 176, model_type = \"large\")\n",
    "\n",
    "myunet.load_data (train_data, test_data)\n",
    "\n",
    "myunet.model.summary()\n",
    "\n",
    "#sess.run(myunet.train_and_predict(model_file, batch_size = 4, nb_epoch = 5))\n",
    "res = myunet.train_and_predict(model_file, batch_size = 4, nb_epoch = 10)\n",
    "#res = myunet.train_with_augmentation(model, batch_size = 4, nb_epoch = 10)\n",
    "\n",
    "myunet.plot_accuracy_and_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Method to visually compare the predictions with actual labels\n",
    "#\n",
    "################################\n",
    "\n",
    "test_data = {}\n",
    "test_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_176_test_images.npy\"\n",
    "test_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_176_test_labels.npy\"\n",
    "\n",
    "ts , tl= load_images_and_labels(test_data)\n",
    "\n",
    "pred = myunet.predictions\n",
    "samples, x, y, z = pred.shape\n",
    "print (samples, pred.max(), pred.min())\n",
    "scores = myunet.model.evaluate (pred, tl, batch_size=1)\n",
    "print (\"Prediction Scores\", scores)\n",
    "pred2 = np.round(pred)\n",
    "scores = myunet.model.evaluate (pred2, tl, batch_size=1)\n",
    "print (\"Prediction Scores after rounding\", scores)\n",
    "##Print few images wih actual labels and predictions\n",
    "for i in range (8,16):\n",
    "    f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "    plt.subplot(131),plt.imshow(ts[i].reshape(x, y))\n",
    "    plt.title('test Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132),plt.imshow(tl[i].reshape(x, y))\n",
    "    plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133),plt.imshow(pred[i].reshape(x, y))\n",
    "    plt.title('Predicted mask'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(132),plt.imshow(ts[i].reshape(256, 256)), plt.imshow(tl[i].reshape(256, 256), 'jet', interpolation='none', alpha=0.5)\n",
    "#     plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(133),plt.imshow(ts[i].reshape(256, 256)), plt.imshow(pred[i].reshape(256, 256), 'jet', interpolation='none', alpha=0.5)\n",
    "#     plt.title('Predicted mask'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# img = imgs[5].reshape(256,256)\n",
    "\n",
    "# plt.imshow(img, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance measures such as precision, recall, f1 score on the model\n",
    "perf = evaluate_performance(tl, pred)\n",
    "print (perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "    plt.subplot(141),plt.imshow(ts[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(tl[i].reshape(x, y))\n",
    "    plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('pred label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(tl[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################\n",
    "#\n",
    "# Model for 256x256 Images\n",
    "# Create a U-Net model, train the model and run the predictions and save the trained weights and predictions\n",
    "#\n",
    "#############################\n",
    "\n",
    "train_data = {}\n",
    "train_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_256_train_images.npy\"\n",
    "train_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_256_train_labels.npy\"\n",
    "test_data = {}\n",
    "test_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_256_test_images.npy\"\n",
    "test_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_256_test_labels.npy\"\n",
    "\n",
    "model_file = UNET_MODEL_DIR+ SOURCE +'_256.hdf5'\n",
    "\n",
    "myunet2 = myUnet(image_size = 256, model_type = \"large\")\n",
    "myunet2.model.summary()\n",
    "\n",
    "myunet2.load_data (train_data, test_data)\n",
    "res = myunet2.train_and_predict(model_file, batch_size = 4, nb_epoch = 10)\n",
    "\n",
    "#res = myunet.train_with_augmentation(model, batch_size = 4, nb_epoch = 10)\n",
    "myunet2.plot_accuracy_and_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Method to visually compare the predictions with actual labels\n",
    "#\n",
    "################################\n",
    "test_data = {}\n",
    "test_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_256_test_images.npy\"\n",
    "test_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_256_test_labels.npy\"\n",
    "\n",
    "ts , tl= load_images_and_labels(test_data)\n",
    "\n",
    "pred = myunet2.predictions\n",
    "samples, x, y, z = pred.shape\n",
    "print (samples, pred.max(), pred.min())\n",
    "\n",
    "scores = myunet2.model.evaluate (pred, tl, batch_size=4)\n",
    "print (\"Prediction Scores\", scores)\n",
    "\n",
    "##Print few images wih actual labels and predictions\n",
    "for i in range (8,16):\n",
    "    f, axs = plt.subplots(1,3,figsize=(10,10))\n",
    "    plt.subplot(131),plt.imshow(ts[i].reshape(x, y))\n",
    "    plt.title('test Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132),plt.imshow(tl[i].reshape(x, y))\n",
    "    plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133),plt.imshow(pred[i].reshape(x, y))\n",
    "    plt.title('Predicted mask'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(132),plt.imshow(ts[i].reshape(256, 256)), plt.imshow(tl[i].reshape(256, 256), 'jet', interpolation='none', alpha=0.5)\n",
    "#     plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(133),plt.imshow(ts[i].reshape(256, 256)), plt.imshow(pred[i].reshape(256, 256), 'jet', interpolation='none', alpha=0.5)\n",
    "#     plt.title('Predicted mask'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to load Pre-trained weights into U-net model and run the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "#  Model for 176x176 images\n",
    "# load the trained weights into U-net model and run the predictions\n",
    "#\n",
    "########################################\n",
    "\n",
    "test_data = {}\n",
    "test_data[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_176_test_images.npy\"\n",
    "test_data[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_176_test_labels.npy\"\n",
    "\n",
    "model_file = UNET_MODEL_DIR+ SOURCE +'_176.hdf5'\n",
    "\n",
    "myunet = myUnet(image_size = 176, model_type = \"large\")\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print (\"Loading Test images and labels...\")\n",
    "ts , tl= load_images_and_labels(test_data)\n",
    "\n",
    "print('-'*30)\n",
    "print (\"Creating U-net model...\")\n",
    "myunet176 = myUnet(image_size = 176, model_type = \"large\")\n",
    "print('-'*30)\n",
    "print (\"Loading the pre-trained weights...\")\n",
    "myunet176.model.load_weights(model_file)\n",
    "print('-'*30)\n",
    "\n",
    "print('Run predictions...')\n",
    "pred = myunet176.model.predict(ts, batch_size=1, verbose=1)\n",
    "samples, x, y, z = pred.shape\n",
    "print (\"Pred data :\", pred.shape, pred.max(), pred.min())\n",
    "print('-'*30)\n",
    "scores = myunet176.model.evaluate (pred, tl, batch_size=1)\n",
    "print (\"Prediction Scores before rounding\", scores)\n",
    "\n",
    "pred2 = np.round(pred)\n",
    "scores = myunet176.model.evaluate (pred2, tl, batch_size=1)\n",
    "print (\"Prediction Scores after rounding\", scores)\n",
    "\n",
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "    plt.subplot(141),plt.imshow(ts[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(tl[i].reshape(x, y))\n",
    "    plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('pred label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(tl[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred2 = np.round(pred)\n",
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "    plt.subplot(141),plt.imshow(ts[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(tl[i].reshape(x, y))\n",
    "    plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('pred label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(tl[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perf = evaluate_performance(tl, pred)\n",
    "print (perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in perf.items():\n",
    "    print(k, v)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# 256x256 images\n",
    "# load the trained weights into U-net model and run the predictions\n",
    "#\n",
    "########################################\n",
    "test_data256 = {}\n",
    "test_data256[\"images\"] = UNET_TRAIN_DIR + \"sunnybrook_256_test_images.npy\"\n",
    "test_data256[\"labels\"] = UNET_TRAIN_DIR + \"sunnybrook_256_test_labels.npy\"\n",
    "\n",
    "model_file = UNET_MODEL_DIR+ SOURCE +'_256.hdf5'\n",
    "\n",
    "\n",
    "myunet256 = myUnet(image_size = 256, model_type = \"large\")\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print (\"Loading Test images and labels...\")\n",
    "ts , tl= load_images_and_labels(test_data256)\n",
    "\n",
    "print('-'*30)\n",
    "print (\"Creating U-net model...\")\n",
    "myunet256 = myUnet(image_size = 256, model_type = \"large\")\n",
    "print('-'*30)\n",
    "print (\"Loading the pre-trained weights...\")\n",
    "myunet256.model.load_weights(model_file)\n",
    "print('-'*30)\n",
    "\n",
    "print('Run predictions...')\n",
    "pred = myunet256.model.predict(ts, batch_size=1, verbose=1)\n",
    "samples, x, y, z = pred.shape\n",
    "print (\"Pred data :\", pred.shape, pred.max(), pred.min())\n",
    "print('-'*30)\n",
    "scores = myunet256.model.evaluate (pred, tl, batch_size=1)\n",
    "print (\"Prediction Scores before rounding\", scores)\n",
    "\n",
    "pred2 = np.round(pred)\n",
    "scores = myunet256.model.evaluate (pred2, tl, batch_size=1)\n",
    "print (\"Prediction Scores after rounding\", scores)\n",
    "\n",
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,4,figsize=(15,15))\n",
    "    plt.subplot(141),plt.imshow(ts[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142),plt.imshow(tl[i].reshape(x, y))\n",
    "    plt.title('test label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('pred label'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144),plt.imshow(tl[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predictions on DSB2 data using pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#\n",
    "# Predictions on DSB2 data using pre-trained weights\n",
    "#\n",
    "#############################\n",
    "\n",
    "\n",
    "img_file = \"/masvol/heartsmart/unet_model/data/dsb118_256.npy\"\n",
    "\n",
    "\n",
    "model_file = UNET_MODEL_DIR+'unet_256.hdf5' #path to save the weights with best model\n",
    "\n",
    "myunet256 = myUnet(image_size = 256, model_type = \"large\")\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print (\"Loading Test images...\")\n",
    "test_imgs = load_images(img_file)\n",
    "print('-'*30)\n",
    "\n",
    "print (\"Creating U-net model...\")\n",
    "myunet256 = myUnet(image_size = 256, model_type = \"large\")\n",
    "print('-'*30)\n",
    "print (\"Loading the pre-trained weights...\")\n",
    "myunet256.model.load_weights(model_file)\n",
    "print('-'*30)\n",
    "\n",
    "print('Run predictions...')\n",
    "pred = myunet256.model.predict(test_imgs, batch_size=1, verbose=1)\n",
    "samples, x, y, z = pred.shape\n",
    "print (\"Pred data :\", pred.shape, pred.max(), pred.min())\n",
    "print('-'*30)\n",
    "\n",
    "pred2 = np.round(pred)\n",
    "\n",
    "\n",
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "    plt.subplot(131),plt.imshow(test_imgs[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132),plt.imshow(pred[i].reshape(x, y))\n",
    "    plt.title('prediction'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133),plt.imshow(test_imgs[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "    plt.subplot(131),plt.imshow(test_imgs[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('prediction'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133),plt.imshow(test_imgs[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_file = \"/masvol/heartsmart/unet_model/data/dsb118_176.npy\"\n",
    "\n",
    "\n",
    "model_file = UNET_MODEL_DIR+'unet_176.hdf5' #path to save the weights with best model\n",
    "\n",
    "myunet176 = myUnet(image_size = 176, model_type = \"large\")\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print (\"Loading Test images...\")\n",
    "test_imgs = load_images(img_file)\n",
    "print('-'*30)\n",
    "\n",
    "print (\"Creating U-net model...\")\n",
    "myunet176 = myUnet(image_size = 176, model_type = \"large\")\n",
    "print('-'*30)\n",
    "print (\"Loading the pre-trained weights...\")\n",
    "myunet176.model.load_weights(model_file)\n",
    "print('-'*30)\n",
    "\n",
    "print('Run predictions...')\n",
    "pred = myunet176.model.predict(test_imgs, batch_size=1, verbose=1)\n",
    "\n",
    "samples, x, y, z = pred.shape\n",
    "print (\"Pred data :\", pred.shape, pred.max(), pred.min())\n",
    "print('-'*30)\n",
    "\n",
    "pred2 = np.round(pred)\n",
    "\n",
    "\n",
    "for i in range (10,15):\n",
    "    f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "    plt.subplot(131),plt.imshow(test_imgs[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('prediction'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133),plt.imshow(test_imgs[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (30,45):\n",
    "    f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "    plt.subplot(131),plt.imshow(test_imgs[i].reshape(x, y))\n",
    "    plt.title('test image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132),plt.imshow(pred2[i].reshape(x, y))\n",
    "    plt.title('prediction'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133),plt.imshow(test_imgs[i].reshape(x, y)), plt.imshow(pred2[i].reshape(x, y), 'binary', interpolation='none', alpha=0.5)\n",
    "    plt.title('overlay'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ............ Backup section  (test code)...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.where(np.logical_and(pred>0, pred<1))\n",
    "b = pred[(pred>0.5) & (pred<1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(b)), b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one():\n",
    "    image_batch, mask_batch = next(validation_generator)\n",
    "    predicted_mask_batch = model.predict(image_batch)\n",
    "    image = image_batch[0]\n",
    "    predicted_mask = predicted_mask_batch[0].reshape(SIZE)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(predicted_mask, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
